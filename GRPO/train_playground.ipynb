{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 9,768,960 || all params: 144,283,968 || trainable%: 6.7706\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from accelerate import Accelerator\n",
    "from utils import *\n",
    "import grpo_utils \n",
    "from utils import load_peft_model, load_tokenizer, get_dataloader, left_pad, load_model\n",
    "\n",
    "model_name = \"../SmolLM-135M\"\n",
    "batch_size = 1\n",
    "n_rollouts = 3\n",
    "buffer_size = 6\n",
    "max_new_tokens = 100\n",
    "\n",
    "# load essentials\n",
    "llm = load_peft_model(model_name) # For full finetuning\n",
    "\n",
    "# llm = load_peft_model(model_name) # For only lora weights training\n",
    "tokenizer = load_tokenizer(model_name)\n",
    "\n",
    "dataloader = get_dataloader(\"syllogism\", tokenizer)\n",
    "\n",
    "optimizer = torch.optim.Adam(llm.parameters(), lr=1e-5)\n",
    "\n",
    "# Initialize accelerator\n",
    "accelerator = Accelerator()\n",
    "llm, tokenizer, dataloader, optimizer = accelerator.prepare(\n",
    "    llm, tokenizer, dataloader, optimizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"head_dim\": 64,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 576,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 1536,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"mlp_bias\": false,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 9,\n",
       "  \"num_hidden_layers\": 30,\n",
       "  \"num_key_value_heads\": 3,\n",
       "  \"pad_token_id\": 2,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"tie_word_embeddings\": true,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.51.3\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 49152\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['validator', 'inputs'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'validator': [{'question': 'Consider these statements:\\n1. No students are humans\\n2. All humans are chefs\\n\\nDoes it logically follow that:\\nSome chefs are humans?\\n(Answer Yes or No)', 'answer': 'Yes', 'metadata': {'source_dataset': 'syllogism', 'source_index': 0, 'premise1': 'No students are humans', 'premise2': 'All humans are chefs', 'selected_premise': 2, 'conclusion': 'Some chefs are humans', 'is_valid': True, 'type': 'inversion'}}, {'question': 'Consider these statements:\\n1. All children are animals\\n2. Some animals are not doctors\\n\\nDoes it logically follow that:\\nSome children are not doctors?\\n(Answer Yes or No)', 'answer': 'Yes', 'metadata': {'source_dataset': 'syllogism', 'source_index': 1, 'premise1': 'All children are animals', 'premise2': 'Some animals are not doctors', 'conclusion': 'Some children are not doctors', 'is_valid': True, 'type': 'syllogism'}}], 'inputs': {'input_ids': tensor([[    2,     2,     1,  9690,   198,   198,    49,  6634,   826, 11122,\n",
      "           284, 20108,    30,   378,  2914, 11421,   253,  1962,    28,   284,\n",
      "           260, 20108, 35242,   357,    30,   198,   504, 11173,   808, 12528,\n",
      "           563,   260, 10115,   980,   281,   260,  1945,   284,   965,  2433,\n",
      "           260,  2914,   198,  3659,   260,  2988,    30,   378, 10115,   980,\n",
      "           284,  2988,   359, 20657,  1127,  2067, 17400,    46, 22577, 17400,\n",
      "            46,   284,   198,    44, 11247,    46, 22577, 11247,    46, 12082,\n",
      "            28,  7827,    28,  2056,    30,    85,  1143,  2067, 17400,    46,\n",
      "         10115,   980,  1535, 22577, 17400,    46,   198,    44, 11247,    46,\n",
      "          2988,  1535, 22577, 11247, 19369,   198,   198,  6248,   441,  5051,\n",
      "           725,  2909,    30,  3315,   441,  2965, 11129,  2909,    30,   198,\n",
      "           198,  2683,   654,   597,   325,  1836,  3480,   411,   260,  2914,\n",
      "          8932,   346,   260,  3393,  2426,  4624,    30,   198, 11101,   260,\n",
      "          4624,   282,   260,  3480,    28,   564,  5482,   260,  1678,  1732,\n",
      "          3413,   411,   260,  2914,    28,   441,   260,  3480,    30,   198,\n",
      "           198, 26111,  1070,   731,  5258,  1163,    28,   469,  3124,  4624,\n",
      "           868,   325,    42,   198,    44, 17400,    46, 10115,   980,  1535,\n",
      "         22577, 17400,    46,   198,    44, 11247,    46,  2988,  1535, 22577,\n",
      "         11247,    46,   198,   198,  7334,  2426,   523,   325, 22440,   411,\n",
      "         28042,   260,   840,  5931,   826,   260,  2067, 11247,    46,  2026,\n",
      "          9617, 11247,    46, 12082,    30,   198,  1589,   314,  2609,   288,\n",
      "          1066,   260,  2120,  4624,    30,   198, 12839,    79,  1527,  4550,\n",
      "            79,  7638,  1519,   288,  1066,   260,  2426,  4624,   523,   966,\n",
      "           281,   253, 15919,    30,   198,     2,   198,     1,  4093,   198,\n",
      "         16865,   623,  7868,    42,   198,    33,    30,  2838,  1058,   359,\n",
      "          2973,   198,    34,    30,  2018,  2973,   359, 22350,   198,   198,\n",
      "         14748,   357, 27177,  1066,   338,    42,   198,  4449, 22350,   359,\n",
      "          2973,    47,   198,    24, 21350,  9230,   355,  2838,    25,     2,\n",
      "           198,     1,   520,  9531,   198],\n",
      "        [    1,  9690,   198,   198,    49,  6634,   826, 11122,   284, 20108,\n",
      "            30,   378,  2914, 11421,   253,  1962,    28,   284,   260, 20108,\n",
      "         35242,   357,    30,   198,   504, 11173,   808, 12528,   563,   260,\n",
      "         10115,   980,   281,   260,  1945,   284,   965,  2433,   260,  2914,\n",
      "           198,  3659,   260,  2988,    30,   378, 10115,   980,   284,  2988,\n",
      "           359, 20657,  1127,  2067, 17400,    46, 22577, 17400,    46,   284,\n",
      "           198,    44, 11247,    46, 22577, 11247,    46, 12082,    28,  7827,\n",
      "            28,  2056,    30,    85,  1143,  2067, 17400,    46, 10115,   980,\n",
      "          1535, 22577, 17400,    46,   198,    44, 11247,    46,  2988,  1535,\n",
      "         22577, 11247, 19369,   198,   198,  6248,   441,  5051,   725,  2909,\n",
      "            30,  3315,   441,  2965, 11129,  2909,    30,   198,   198,  2683,\n",
      "           654,   597,   325,  1836,  3480,   411,   260,  2914,  8932,   346,\n",
      "           260,  3393,  2426,  4624,    30,   198, 11101,   260,  4624,   282,\n",
      "           260,  3480,    28,   564,  5482,   260,  1678,  1732,  3413,   411,\n",
      "           260,  2914,    28,   441,   260,  3480,    30,   198,   198, 26111,\n",
      "          1070,   731,  5258,  1163,    28,   469,  3124,  4624,   868,   325,\n",
      "            42,   198,    44, 17400,    46, 10115,   980,  1535, 22577, 17400,\n",
      "            46,   198,    44, 11247,    46,  2988,  1535, 22577, 11247,    46,\n",
      "           198,   198,  7334,  2426,   523,   325, 22440,   411, 28042,   260,\n",
      "           840,  5931,   826,   260,  2067, 11247,    46,  2026,  9617, 11247,\n",
      "            46, 12082,    30,   198,  1589,   314,  2609,   288,  1066,   260,\n",
      "          2120,  4624,    30,   198, 12839,    79,  1527,  4550,    79,  7638,\n",
      "          1519,   288,  1066,   260,  2426,  4624,   523,   966,   281,   253,\n",
      "         15919,    30,   198,     2,   198,     1,  4093,   198, 16865,   623,\n",
      "          7868,    42,   198,    33,    30,  2018,  1122,   359,  2355,   198,\n",
      "            34,    30,  2015,  2355,   359,   441,  6093,   198,   198, 14748,\n",
      "           357, 27177,  1066,   338,    42,   198,  4449,  1122,   359,   441,\n",
      "          6093,    47,   198,    24, 21350,  9230,   355,  2838,    25,     2,\n",
      "           198,     1,   520,  9531,   198]], device='cuda:0'), 'attention_mask': tensor([[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}}\n"
     ]
    }
   ],
   "source": [
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"inputs\"][\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_end|><|im_end|><|im_start|>system\n",
      "\n",
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
      "The assistant first thinks about the reasoning process in the mind and then provides the user\n",
      "with the answer. The reasoning process and answer are enclosed within <think> </think> and\n",
      "<answer> </answer> tags, respectively, i.e., <think> reasoning process here </think>\n",
      "<answer> answer here </answer>.\n",
      "\n",
      "Do not generate new code. Do not write python code.\n",
      "\n",
      "You may also be given examples by the user telling you the expected response format.\n",
      "Follow the format of the examples, but solve the specific problem asked by the user, not the examples.\n",
      "\n",
      "Very important - Remember again, your output format should be:\n",
      "<think> reasoning process here </think>\n",
      "<answer> answer here </answer>\n",
      "\n",
      "Your response will be scored by extracting the substring between the <answer>...</answer> tags.\n",
      "It is critical to follow the above format.\n",
      "feature_extraction_utilsling to follow the response format will result in a penalty.\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "Consider these statements:\n",
      "1. No students are humans\n",
      "2. All humans are chefs\n",
      "\n",
      "Does it logically follow that:\n",
      "Some chefs are humans?\n",
      "(Answer Yes or No)<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(batch[\"inputs\"][\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_end|><|im_end|><|im_start|>system\n",
      "\n",
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
      "The assistant first thinks about the reasoning process in the mind and then provides the user\n",
      "with the answer. The reasoning process and answer are enclosed within <think> </think> and\n",
      "<answer> </answer> tags, respectively, i.e., <think> reasoning process here </think>\n",
      "<answer> answer here </answer>.\n",
      "\n",
      "Do not generate new code. Do not write python code.\n",
      "\n",
      "You may also be given examples by the user telling you the expected response format.\n",
      "Follow the format of the examples, but solve the specific problem asked by the user, not the examples.\n",
      "\n",
      "Very important - Remember again, your output format should be:\n",
      "<think> reasoning process here </think>\n",
      "<answer> answer here </answer>\n",
      "\n",
      "Your response will be scored by extracting the substring between the <answer>...</answer> tags.\n",
      "It is critical to follow the above format.\n",
      "feature_extraction_utilsling to follow the response format will result in a penalty.\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "Consider these statements:\n",
      "1. No students are humans\n",
      "2. All humans are chefs\n",
      "\n",
      "Does it logically follow that:\n",
      "Some chefs are humans?\n",
      "(Answer Yes or No)<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(batch[\"inputs\"][\"input_ids\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Consider these statements:\\n1. All children are animals\\n2. Some animals are not doctors\\n\\nDoes it logically follow that:\\nSome children are not doctors?\\n(Answer Yes or No)', 'answer': 'Yes', 'metadata': {'source_dataset': 'syllogism', 'source_index': 1, 'premise1': 'All children are animals', 'premise2': 'Some animals are not doctors', 'conclusion': 'Some children are not doctors', 'is_valid': True, 'type': 'syllogism'}}\n"
     ]
    }
   ],
   "source": [
    "print(batch[\"validator\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format rewards: [1. 1. 1. 1. 1. 1.]\n",
      "Correctness rewards: [1. 1. 1. 0. 1. 0.]\n",
      "Combined rewards: [1.   1.   1.   0.15 1.   0.15]\n"
     ]
    }
   ],
   "source": [
    "llm, tokenizer, dataloader, optimizer = llm, tokenizer, dataloader, optimizer\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "\n",
    "input_ids = batch[\"inputs\"][\"input_ids\"]\n",
    "\n",
    "\n",
    "attention_mask = batch[\"inputs\"][\"attention_mask\"]\n",
    "validator = batch[\"validator\"]\n",
    "input_size = input_ids.shape[1]\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    full_responses = llm.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=max_new_tokens, # 100\n",
    "        do_sample=True,\n",
    "        top_p=0.95,\n",
    "        num_return_sequences=n_rollouts,\n",
    "        temperature=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    \n",
    "    assistant_responses = full_responses[:, input_size:]\n",
    "\n",
    "    # Calculate the logits for each selected tokens\n",
    "    log_probs = grpo_utils.calculate_logits(llm, full_responses, attention_mask)\n",
    "\n",
    "    # Convert tokens to string\n",
    "    decoded_responses = tokenizer.batch_decode(\n",
    "        assistant_responses, skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    # model_responses = [batch_size*n_rollouts, max_new_tokens]\n",
    "    rewards, format_rewards, correctness_rewards = grpo_utils.calculate_rewards(\n",
    "        decoded_responses, np.repeat(validator, n_rollouts)\n",
    "    )\n",
    "\n",
    "    # advantages = [batch_size, n_rollouts]\n",
    "    rewards = np.reshape(rewards, [2, n_rollouts])\n",
    "    advantages = (rewards - np.mean(rewards, axis=1, keepdims=True)) / (\n",
    "        np.std(rewards, axis=1, keepdims=True) + 1e-8\n",
    "    )\n",
    "\n",
    "    advantages = advantages.reshape(-1, 1)\n",
    "    advantages = torch.tensor(advantages, dtype=torch.float32).to(llm.device)\n",
    "\n",
    "    padded_tokens = (full_responses != tokenizer.eos_token_id).int()\n",
    "    response_start_idx = padded_tokens.argmax(axis=-1)\n",
    "    response_end_idx = padded_tokens.shape[1] - torch.flip(\n",
    "        padded_tokens, dims=[1]\n",
    "    ).argmax(dim=1)\n",
    "\n",
    "    response_mask = torch.zeros_like(padded_tokens)\n",
    "    for i in range(len(response_mask)):\n",
    "        response_mask[i, input_size : response_end_idx[i]] = 1\n",
    "experience = [\n",
    "    {\n",
    "        \"input_sequence\": full_responses[\n",
    "            i, response_start_idx[i] : response_end_idx[i]\n",
    "        ],\n",
    "        \"log_probs\": log_probs[i, response_start_idx[i] : response_end_idx[i]],\n",
    "        \"response_mask\": response_mask[\n",
    "            i, response_start_idx[i] : response_end_idx[i]\n",
    "        ],\n",
    "        \"advantages\": advantages[i],\n",
    "    }\n",
    "    for i in range(advantages.shape[0])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 385])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_responses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "\n",
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
      "The assistant first thinks about the reasoning process in the mind and then provides the user\n",
      "with the answer. The reasoning process and answer are enclosed within <think> </think> and\n",
      "<answer> </answer> tags, respectively, i.e., <think> reasoning process here </think>\n",
      "<answer> answer here </answer>.\n",
      "\n",
      "Do not generate new code. Do not write python code.\n",
      "\n",
      "You may also be given examples by the user telling you the expected response format.\n",
      "Follow the format of the examples, but solve the specific problem asked by the user, not the examples.\n",
      "\n",
      "Very important - Remember again, your output format should be:\n",
      "<think> reasoning process here </think>\n",
      "<answer> answer here </answer>\n",
      "\n",
      "Your response will be scored by extracting the substring between the <answer>...</answer> tags.\n",
      "It is critical to follow the above format.\n",
      "feature_extraction_utilsling to follow the response format will result in a penalty.\n",
      "\n",
      "user\n",
      "Consider these statements:\n",
      "1. No students are humans\n",
      "2. All humans are chefs\n",
      "\n",
      "Does it logically follow that:\n",
      "Some chefs are humans?\n",
      "(Answer Yes or No)\n",
      "assistant\n",
      "<think>Given premise 1: No students are humans. This means there is no direct connection between students and humans. Premise 2 states all humans are chefs. Therefore, the conclusion \"Some chefs are humans\" logically follows.</think>\n",
      "<answer> Yes </answer>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(full_responses, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Consider these statements:\\n1. All children are animals\\n2. Some animals are not doctors\\n\\nDoes it logically follow that:\\nSome children are not doctors?\\n(Answer Yes or No)',\n",
       " 'answer': 'Yes',\n",
       " 'metadata': {'source_dataset': 'syllogism',\n",
       "  'source_index': 1,\n",
       "  'premise1': 'All children are animals',\n",
       "  'premise2': 'Some animals are not doctors',\n",
       "  'conclusion': 'Some children are not doctors',\n",
       "  'is_valid': True,\n",
       "  'type': 'syllogism'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>From the premises: \"No students are humans\" means no students are humans, which does not necessarily mean any students are humans. \"All humans are chefs\" says there is at least one chef in each of the humans. \"In fact, no other group of humans could be outside the category of chefs because humans and chefs overlap, which means the set of chefs must be a subset of humans.\" Therefore, the conclusion \"Some chefs are humans\" logically follows because the \"some\"\n"
     ]
    }
   ],
   "source": [
    "assistant_responses = full_responses[:, input_size:]\n",
    "assistant_responses = tokenizer.batch_decode(assistant_responses,skip_special_tokens=True)\n",
    "print(assistant_responses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0225 0.0225 1.     0.0225 1.     0.0225]\n"
     ]
    }
   ],
   "source": [
    "print(rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids.shape: torch.Size([2, 285])\n",
      "full_responses.shape: torch.Size([6, 385])\n",
      "len(decoded_responses): 6\n",
      "validator: [{'question': 'Consider these statements:\\n1. No students are humans\\n2. All humans are chefs\\n\\nDoes it logically follow that:\\nSome chefs are humans?\\n(Answer Yes or No)', 'answer': 'Yes', 'metadata': {'source_dataset': 'syllogism', 'source_index': 0, 'premise1': 'No students are humans', 'premise2': 'All humans are chefs', 'selected_premise': 2, 'conclusion': 'Some chefs are humans', 'is_valid': True, 'type': 'inversion'}}, {'question': 'Consider these statements:\\n1. All children are animals\\n2. Some animals are not doctors\\n\\nDoes it logically follow that:\\nSome children are not doctors?\\n(Answer Yes or No)', 'answer': 'Yes', 'metadata': {'source_dataset': 'syllogism', 'source_index': 1, 'premise1': 'All children are animals', 'premise2': 'Some animals are not doctors', 'conclusion': 'Some children are not doctors', 'is_valid': True, 'type': 'syllogism'}}]\n",
      "np.repeat(validator, n_rollouts): [{'question': 'Consider these statements:\\n1. No students are humans\\n2. All humans are chefs\\n\\nDoes it logically follow that:\\nSome chefs are humans?\\n(Answer Yes or No)', 'answer': 'Yes', 'metadata': {'source_dataset': 'syllogism', 'source_index': 0, 'premise1': 'No students are humans', 'premise2': 'All humans are chefs', 'selected_premise': 2, 'conclusion': 'Some chefs are humans', 'is_valid': True, 'type': 'inversion'}}\n",
      " {'question': 'Consider these statements:\\n1. No students are humans\\n2. All humans are chefs\\n\\nDoes it logically follow that:\\nSome chefs are humans?\\n(Answer Yes or No)', 'answer': 'Yes', 'metadata': {'source_dataset': 'syllogism', 'source_index': 0, 'premise1': 'No students are humans', 'premise2': 'All humans are chefs', 'selected_premise': 2, 'conclusion': 'Some chefs are humans', 'is_valid': True, 'type': 'inversion'}}\n",
      " {'question': 'Consider these statements:\\n1. No students are humans\\n2. All humans are chefs\\n\\nDoes it logically follow that:\\nSome chefs are humans?\\n(Answer Yes or No)', 'answer': 'Yes', 'metadata': {'source_dataset': 'syllogism', 'source_index': 0, 'premise1': 'No students are humans', 'premise2': 'All humans are chefs', 'selected_premise': 2, 'conclusion': 'Some chefs are humans', 'is_valid': True, 'type': 'inversion'}}\n",
      " {'question': 'Consider these statements:\\n1. All children are animals\\n2. Some animals are not doctors\\n\\nDoes it logically follow that:\\nSome children are not doctors?\\n(Answer Yes or No)', 'answer': 'Yes', 'metadata': {'source_dataset': 'syllogism', 'source_index': 1, 'premise1': 'All children are animals', 'premise2': 'Some animals are not doctors', 'conclusion': 'Some children are not doctors', 'is_valid': True, 'type': 'syllogism'}}\n",
      " {'question': 'Consider these statements:\\n1. All children are animals\\n2. Some animals are not doctors\\n\\nDoes it logically follow that:\\nSome children are not doctors?\\n(Answer Yes or No)', 'answer': 'Yes', 'metadata': {'source_dataset': 'syllogism', 'source_index': 1, 'premise1': 'All children are animals', 'premise2': 'Some animals are not doctors', 'conclusion': 'Some children are not doctors', 'is_valid': True, 'type': 'syllogism'}}\n",
      " {'question': 'Consider these statements:\\n1. All children are animals\\n2. Some animals are not doctors\\n\\nDoes it logically follow that:\\nSome children are not doctors?\\n(Answer Yes or No)', 'answer': 'Yes', 'metadata': {'source_dataset': 'syllogism', 'source_index': 1, 'premise1': 'All children are animals', 'premise2': 'Some animals are not doctors', 'conclusion': 'Some children are not doctors', 'is_valid': True, 'type': 'syllogism'}}]\n"
     ]
    }
   ],
   "source": [
    "print(f\"input_ids.shape: {input_ids.shape}\")\n",
    "print(f\"full_responses.shape: {full_responses.shape}\")\n",
    "print(f\"len(decoded_responses): {len(decoded_responses)}\")\n",
    "print(f\"validator: {validator}\")  # Should be 1 element if batch size = 1\n",
    "print(f\"np.repeat(validator, n_rollouts): {np.repeat(validator, n_rollouts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grpo_utils.extract_answer(decoded_responses[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.70710677 -0.70710677  1.41421353]\n",
      " [-0.70710677  1.41421353 -0.70710677]]\n"
     ]
    }
   ],
   "source": [
    "# advantages = [batch_size, n_rollouts]\n",
    "rewards = np.reshape(rewards, [2, n_rollouts])\n",
    "advantages = (rewards - np.mean(rewards, axis=1, keepdims=True)) / (\n",
    "    np.std(rewards, axis=1, keepdims=True) + 1e-8\n",
    ")\n",
    "\n",
    "print(advantages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantages.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999998, 0.99999998])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantages.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mexperience\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m())  \u001b[38;5;66;03m# Output: ['name', 'age', 'city']\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "print(experience.keys())  # Output: ['name', 'age', 'city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience = [\n",
    "    {\"input_sequence\": full_responses[i, response_start_idx[i] : response_end_idx[i]],\n",
    "     \"log_probs\": log_probs[i, response_start_idx[i] : response_end_idx[i]],\n",
    "     \"response_mask\": response_mask[i, response_start_idx[i] : response_end_idx[i]],\n",
    "     \"advantages\": advantages[i],\n",
    "    }\n",
    "    for i in range(advantages.shape[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_sequence', 'log_probs', 'response_mask', 'advantages'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Step\n",
    "\n",
    "Run this block a couple of times and you should see the loss go down!\n",
    "If it doesn't, decrease the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0093, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "full_sequence = left_pad([b[\"input_sequence\"] for b in experience]).to(\n",
    "    accelerator.device\n",
    ")\n",
    "attention_mask = left_pad(\n",
    "    [torch.ones_like(b[\"input_sequence\"]) for b in experience], 0\n",
    ").to(accelerator.device)\n",
    "old_log_probs = left_pad([b[\"log_probs\"] for b in experience]).to(accelerator.device)\n",
    "response_mask = left_pad([b[\"response_mask\"] for b in experience]).to(accelerator.device)\n",
    "\n",
    "advantages = (\n",
    "    torch.cat([b[\"advantages\"] for b in experience], dim=0)\n",
    "    .unsqueeze(-1)\n",
    "    .to(accelerator.device)\n",
    ")\n",
    "\n",
    "log_probs = grpo_utils.calculate_logits(llm, full_sequence, attention_mask)\n",
    "\n",
    "loss = grpo_utils.calculate_grpo_loss(\n",
    "    log_probs=log_probs,\n",
    "    old_log_probs=old_log_probs,\n",
    "    response_mask=response_mask,\n",
    "    advantages=advantages,\n",
    ")\n",
    "print(loss)\n",
    "\n",
    "accelerator.backward(loss)\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(18.7607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(58.1063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.9072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.9230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(12.1451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(22.2942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(29.5974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(35.5987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.1083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.5726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(18.9188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(11.8033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(30.8511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(12.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(30.2147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.1353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(6.3121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.9268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(11.2472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.3809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(35.2155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.1472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(16.7218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.3641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(8.5905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.8526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.3837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(42.1392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.2379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.3867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(42.7850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(10.4954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(10.9914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(13.1755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.2295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.8749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.5333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.0194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.9040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(6.1616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(10.0403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7347e-10, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(23.3340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(59.1985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(11.9428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(6.9270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(17.3634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.7244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.0623e-10, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2482, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    input_ids = batch[\"inputs\"][\"input_ids\"]\n",
    "    attention_mask = batch[\"inputs\"][\"attention_mask\"]\n",
    "    validator = batch[\"validator\"]\n",
    "    batch_size = input_ids.shape[0]\n",
    "    input_size = input_ids.shape[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        full_responses = llm.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=max_new_tokens,  # 100\n",
    "            do_sample=True,\n",
    "            top_p=0.95,\n",
    "            num_return_sequences=n_rollouts,\n",
    "            temperature=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "        assistant_responses = full_responses[:, input_size:]\n",
    "\n",
    "        # Calculate logits etc.\n",
    "        log_probs = grpo_utils.calculate_logits(llm, full_responses, attention_mask)\n",
    "\n",
    "        decoded_responses = tokenizer.batch_decode(\n",
    "            assistant_responses, skip_special_tokens=True\n",
    "        )\n",
    "\n",
    "        # Repeat validator for n_rollouts times per input\n",
    "        rewards = grpo_utils.calculate_rewards(\n",
    "            decoded_responses, np.repeat(validator, n_rollouts)\n",
    "        )\n",
    "\n",
    "        rewards = np.reshape(rewards, [batch_size, n_rollouts])\n",
    "        advantages = (rewards - np.mean(rewards, axis=1, keepdims=True)) / (\n",
    "            np.std(rewards, axis=1, keepdims=True) + 1e-8\n",
    "        )\n",
    "        advantages = advantages.reshape(-1, 1)\n",
    "        advantages = torch.tensor(advantages, dtype=torch.float32).to(llm.device)\n",
    "\n",
    "        padded_tokens = (full_responses != tokenizer.eos_token_id).int()\n",
    "        response_start_idx = padded_tokens.argmax(axis=-1)\n",
    "        response_end_idx = padded_tokens.shape[1] - torch.flip(\n",
    "            padded_tokens, dims=[1]\n",
    "        ).argmax(dim=1)\n",
    "\n",
    "        response_mask = torch.zeros_like(padded_tokens)\n",
    "        for i in range(len(response_mask)):\n",
    "            response_mask[i, input_size : response_end_idx[i]] = 1\n",
    "\n",
    "        experience = [\n",
    "            {\n",
    "                \"input_sequence\": full_responses[\n",
    "                    i, response_start_idx[i] : response_end_idx[i]\n",
    "                ],\n",
    "                \"log_probs\": log_probs[i, response_start_idx[i] : response_end_idx[i]],\n",
    "                \"response_mask\": response_mask[\n",
    "                    i, response_start_idx[i] : response_end_idx[i]\n",
    "                ],\n",
    "                \"advantages\": advantages[i],\n",
    "            }\n",
    "            for i in range(advantages.shape[0])\n",
    "        ]\n",
    "\n",
    "    # Cell 2 logic inside loop\n",
    "    full_sequence = left_pad([b[\"input_sequence\"] for b in experience]).to(accelerator.device)\n",
    "    attention_mask = left_pad([torch.ones_like(b[\"input_sequence\"]) for b in experience], 0).to(accelerator.device)\n",
    "    old_log_probs = left_pad([b[\"log_probs\"] for b in experience]).to(accelerator.device)\n",
    "    response_mask = left_pad([b[\"response_mask\"] for b in experience]).to(accelerator.device)\n",
    "    advantages = torch.cat([b[\"advantages\"] for b in experience], dim=0).unsqueeze(-1).to(accelerator.device)\n",
    "\n",
    "    log_probs = grpo_utils.calculate_logits(llm, full_sequence, attention_mask)\n",
    "\n",
    "    loss = grpo_utils.calculate_grpo_loss(\n",
    "        log_probs=log_probs,\n",
    "        old_log_probs=old_log_probs,\n",
    "        response_mask=response_mask,\n",
    "        advantages=advantages,\n",
    "    )\n",
    "    print(loss)\n",
    "\n",
    "    accelerator.backward(loss)\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Epoch 1, Batch 1, Loss: -0.0342\n",
      "Epoch 1, Batch 2, Loss: 5.1182\n",
      "Epoch 1, Batch 3, Loss: -0.0501\n",
      "Epoch 1, Batch 4, Loss: -0.0354\n",
      "Epoch 1, Batch 5, Loss: 0.2868\n",
      "Epoch 1, Batch 6, Loss: 126.2230\n",
      "Epoch 1, Batch 7, Loss: -0.0557\n",
      "Epoch 1, Batch 8, Loss: -0.0503\n",
      "Epoch 1, Batch 9, Loss: -0.0211\n",
      "Epoch 1, Batch 10, Loss: 1.7522\n",
      "Epoch 1, Batch 11, Loss: 208.6097\n",
      "Epoch 1, Batch 12, Loss: 629.1606\n",
      "Epoch 1, Batch 13, Loss: 0.5448\n",
      "Epoch 1, Batch 14, Loss: 91.0846\n",
      "Epoch 1, Batch 15, Loss: 1.6441\n",
      "Epoch 1, Batch 16, Loss: 36.1148\n",
      "Epoch 1, Batch 17, Loss: -0.0473\n",
      "Epoch 1, Batch 18, Loss: 9.2348\n",
      "Epoch 1, Batch 19, Loss: 1.2691\n",
      "Epoch 1, Batch 20, Loss: -0.0451\n",
      "Epoch 1, Batch 21, Loss: -0.0721\n",
      "Epoch 1, Batch 22, Loss: 88.9724\n",
      "Epoch 1, Batch 23, Loss: 0.9981\n",
      "Epoch 1, Batch 24, Loss: -0.0566\n",
      "Epoch 1, Batch 25, Loss: -0.0109\n",
      "Epoch 1, Batch 26, Loss: 15.8651\n",
      "Epoch 1, Batch 27, Loss: 18.2337\n",
      "Epoch 1, Batch 28, Loss: 5.2963\n",
      "Epoch 1, Batch 29, Loss: 5.0498\n",
      "Epoch 1, Batch 30, Loss: -0.0084\n",
      "Epoch 1, Batch 31, Loss: -0.0531\n",
      "Epoch 1, Batch 32, Loss: 0.3267\n",
      "Epoch 1, Batch 33, Loss: -0.0214\n",
      "Epoch 1, Batch 34, Loss: -0.0290\n",
      "Epoch 1, Batch 35, Loss: -0.0344\n",
      "Epoch 1, Batch 36, Loss: 2.2443\n",
      "Epoch 1, Batch 37, Loss: -0.0122\n",
      "Epoch 1, Batch 38, Loss: 0.0558\n",
      "Epoch 1, Batch 39, Loss: 4.9184\n",
      "Epoch 1, Batch 40, Loss: -0.0177\n",
      "Epoch 1, Batch 41, Loss: -0.0599\n",
      "Epoch 1, Batch 42, Loss: -0.0125\n",
      "Epoch 1, Batch 43, Loss: 0.7679\n",
      "Epoch 1, Batch 44, Loss: -0.0246\n",
      "Epoch 1, Batch 45, Loss: -0.0419\n",
      "Epoch 1, Batch 46, Loss: 13.5673\n",
      "Epoch 1, Batch 47, Loss: -0.0494\n",
      "Epoch 1, Batch 48, Loss: 16.1331\n",
      "Epoch 1, Batch 49, Loss: -0.0249\n",
      "Epoch 1, Batch 50, Loss: 15.2735\n",
      "Epoch 1, Batch 51, Loss: 67.2662\n",
      "Epoch 1, Batch 52, Loss: 18.7390\n",
      "Epoch 1, Batch 53, Loss: -0.0475\n",
      "Epoch 1, Batch 54, Loss: -0.0480\n",
      "Epoch 1, Batch 55, Loss: 1.1339\n",
      "Epoch 1, Batch 56, Loss: 1.8686\n",
      "Epoch 1, Batch 57, Loss: 5.6083\n",
      "Epoch 1, Batch 58, Loss: -0.0254\n",
      "Epoch 1, Batch 59, Loss: -0.0634\n",
      "Epoch 1, Batch 60, Loss: 26.7408\n",
      "Epoch 1, Batch 61, Loss: -0.0492\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "num_epochs = 5  # set how many epochs you want\n",
    "log_file = \"training_log.txt\"\n",
    "model_save_path = \"./saved_model\"\n",
    "\n",
    "# Create folder if it doesn't exist\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "training_losses = []\n",
    "\n",
    "with open(log_file, \"w\") as f_log:\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        f_log.write(f\"Epoch {epoch + 1}/{num_epochs}\\n\")\n",
    "\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            input_ids = batch[\"inputs\"][\"input_ids\"]\n",
    "            attention_mask = batch[\"inputs\"][\"attention_mask\"]\n",
    "            validator = batch[\"validator\"]\n",
    "            batch_size = input_ids.shape[0]\n",
    "            input_size = input_ids.shape[1]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                full_responses = llm.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    max_new_tokens=max_new_tokens,  # 100\n",
    "                    do_sample=True,\n",
    "                    top_p=0.95,\n",
    "                    num_return_sequences=n_rollouts,\n",
    "                    temperature=1,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                )\n",
    "                assistant_responses = full_responses[:, input_size:]\n",
    "\n",
    "                # Calculate logits etc.\n",
    "                log_probs = grpo_utils.calculate_logits(llm, full_responses, attention_mask)\n",
    "\n",
    "                decoded_responses = tokenizer.batch_decode(\n",
    "                    assistant_responses, skip_special_tokens=True\n",
    "                )\n",
    "\n",
    "                rewards = grpo_utils.calculate_rewards(\n",
    "                    decoded_responses, np.repeat(validator, n_rollouts)\n",
    "                )\n",
    "\n",
    "                rewards = np.reshape(rewards, [batch_size, n_rollouts])\n",
    "                advantages = (rewards - np.mean(rewards, axis=1, keepdims=True)) / (\n",
    "                    np.std(rewards, axis=1, keepdims=True) + 1e-8\n",
    "                )\n",
    "                advantages = advantages.reshape(-1, 1)\n",
    "                advantages = torch.tensor(advantages, dtype=torch.float32).to(llm.device)\n",
    "\n",
    "                padded_tokens = (full_responses != tokenizer.eos_token_id).int()\n",
    "                response_start_idx = padded_tokens.argmax(axis=-1)\n",
    "                response_end_idx = padded_tokens.shape[1] - torch.flip(\n",
    "                    padded_tokens, dims=[1]\n",
    "                ).argmax(dim=1)\n",
    "\n",
    "                response_mask = torch.zeros_like(padded_tokens)\n",
    "                for i in range(len(response_mask)):\n",
    "                    response_mask[i, input_size : response_end_idx[i]] = 1\n",
    "\n",
    "                experience = [\n",
    "                    {\n",
    "                        \"input_sequence\": full_responses[\n",
    "                            i, response_start_idx[i] : response_end_idx[i]\n",
    "                        ],\n",
    "                        \"log_probs\": log_probs[i, response_start_idx[i] : response_end_idx[i]],\n",
    "                        \"response_mask\": response_mask[\n",
    "                            i, response_start_idx[i] : response_end_idx[i]\n",
    "                        ],\n",
    "                        \"advantages\": advantages[i],\n",
    "                    }\n",
    "                    for i in range(advantages.shape[0])\n",
    "                ]\n",
    "\n",
    "            full_sequence = left_pad([b[\"input_sequence\"] for b in experience]).to(accelerator.device)\n",
    "            attention_mask = left_pad([torch.ones_like(b[\"input_sequence\"]) for b in experience], 0).to(accelerator.device)\n",
    "            old_log_probs = left_pad([b[\"log_probs\"] for b in experience]).to(accelerator.device)\n",
    "            response_mask = left_pad([b[\"response_mask\"] for b in experience]).to(accelerator.device)\n",
    "            advantages = torch.cat([b[\"advantages\"] for b in experience], dim=0).unsqueeze(-1).to(accelerator.device)\n",
    "\n",
    "            log_probs = grpo_utils.calculate_logits(llm, full_sequence, attention_mask)\n",
    "\n",
    "            loss = grpo_utils.calculate_grpo_loss(\n",
    "                log_probs=log_probs,\n",
    "                old_log_probs=old_log_probs,\n",
    "                response_mask=response_mask,\n",
    "                advantages=advantages,\n",
    "            )\n",
    "\n",
    "            print(f\"Epoch {epoch+1}, Batch {batch_idx+1}, Loss: {loss.item():.4f}\")\n",
    "            f_log.write(f\"Epoch {epoch+1}, Batch {batch_idx+1}, Loss: {loss.item():.4f}\\n\")\n",
    "            f_log.flush()\n",
    "\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "# Save final model and tokenizer after training\n",
    "print(f\"Saving model to {model_save_path}\")\n",
    "llm.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_df(idx, clip_epsilon=1):\n",
    "    num_tokens = 25\n",
    "    importance_sampling_ratio = torch.exp(log_probs - old_log_probs)\n",
    "\n",
    "    unclipped_ratio = importance_sampling_ratio\n",
    "    clipped_ratio = torch.clamp(\n",
    "        importance_sampling_ratio, 1 - clip_epsilon, 1 + clip_epsilon\n",
    "    )\n",
    "\n",
    "    clipped_loss = clipped_ratio * advantages\n",
    "    unclipped_loss = unclipped_ratio * advantages\n",
    "\n",
    "    loss = -torch.min(unclipped_loss, clipped_loss)\n",
    "    tokens = [tokenizer.decode([token]) for token in full_sequence[idx, -num_tokens:]]\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"advantages\": advantages[idx].item(),\n",
    "            \"old_log_probs\": old_log_probs[idx, -num_tokens:].detach().cpu().float().numpy(),\n",
    "            \"log_probs\": log_probs[idx, -num_tokens:].detach().cpu().float().numpy(),\n",
    "            \"ratio\": importance_sampling_ratio[idx, -num_tokens:].detach().cpu().float().numpy(),\n",
    "            \"unclipped_ratio\": unclipped_ratio[idx, -num_tokens:].detach().cpu().float().numpy(),\n",
    "            f\"clipped_ratio (eps={clip_epsilon})\": clipped_ratio[idx, -num_tokens:].detach().cpu().float().numpy(),\n",
    "            \"unclipped_loss\": unclipped_loss[idx, -num_tokens:].detach().cpu().float().numpy(),\n",
    "            f\"clipped_loss (eps={clip_epsilon})\": clipped_loss[idx, -num_tokens:].detach().cpu().float().numpy(),\n",
    "            \"loss\": loss[idx, -num_tokens:].detach().cpu().float().numpy(),\n",
    "        }\n",
    "    )\n",
    "    df.index = tokens\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>advantages</th>\n",
       "      <th>old_log_probs</th>\n",
       "      <th>log_probs</th>\n",
       "      <th>ratio</th>\n",
       "      <th>unclipped_ratio</th>\n",
       "      <th>clipped_ratio (eps=0.2)</th>\n",
       "      <th>unclipped_loss</th>\n",
       "      <th>clipped_loss (eps=0.2)</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-9.562500</td>\n",
       "      <td>-9.187500</td>\n",
       "      <td>1.453125</td>\n",
       "      <td>1.453125</td>\n",
       "      <td>1.203125</td>\n",
       "      <td>-1.027514</td>\n",
       "      <td>-0.850737</td>\n",
       "      <td>1.027514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>some</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-15.687500</td>\n",
       "      <td>-16.375000</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>-0.356315</td>\n",
       "      <td>-0.566237</td>\n",
       "      <td>0.566237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chefs</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-23.250000</td>\n",
       "      <td>-23.125000</td>\n",
       "      <td>1.132812</td>\n",
       "      <td>1.132812</td>\n",
       "      <td>1.132812</td>\n",
       "      <td>-0.801019</td>\n",
       "      <td>-0.801019</td>\n",
       "      <td>0.801019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-14.562500</td>\n",
       "      <td>-14.437500</td>\n",
       "      <td>1.132812</td>\n",
       "      <td>1.132812</td>\n",
       "      <td>1.132812</td>\n",
       "      <td>-0.801019</td>\n",
       "      <td>-0.801019</td>\n",
       "      <td>0.801019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humans</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-17.500000</td>\n",
       "      <td>-17.625000</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>-0.624242</td>\n",
       "      <td>-0.624242</td>\n",
       "      <td>0.624242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-13.812500</td>\n",
       "      <td>-14.250000</td>\n",
       "      <td>0.644531</td>\n",
       "      <td>0.644531</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>-0.455752</td>\n",
       "      <td>-0.566237</td>\n",
       "      <td>0.566237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\n</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-0.259766</td>\n",
       "      <td>-0.207031</td>\n",
       "      <td>1.054688</td>\n",
       "      <td>1.054688</td>\n",
       "      <td>1.054688</td>\n",
       "      <td>-0.745776</td>\n",
       "      <td>-0.745776</td>\n",
       "      <td>0.745776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\n</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-12.375000</td>\n",
       "      <td>-13.125000</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>-0.334218</td>\n",
       "      <td>-0.566237</td>\n",
       "      <td>0.566237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Therefore</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-23.875000</td>\n",
       "      <td>-23.750000</td>\n",
       "      <td>1.132812</td>\n",
       "      <td>1.132812</td>\n",
       "      <td>1.132812</td>\n",
       "      <td>-0.801019</td>\n",
       "      <td>-0.801019</td>\n",
       "      <td>0.801019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-14.687500</td>\n",
       "      <td>-14.312500</td>\n",
       "      <td>1.453125</td>\n",
       "      <td>1.453125</td>\n",
       "      <td>1.203125</td>\n",
       "      <td>-1.027514</td>\n",
       "      <td>-0.850737</td>\n",
       "      <td>1.027514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-11.437500</td>\n",
       "      <td>-11.687500</td>\n",
       "      <td>0.777344</td>\n",
       "      <td>0.777344</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>-0.549664</td>\n",
       "      <td>-0.566237</td>\n",
       "      <td>0.566237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conclusion</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-12.125000</td>\n",
       "      <td>-12.250000</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>-0.624242</td>\n",
       "      <td>-0.624242</td>\n",
       "      <td>0.624242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-22.500000</td>\n",
       "      <td>-21.750000</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>1.203125</td>\n",
       "      <td>-1.491552</td>\n",
       "      <td>-0.850737</td>\n",
       "      <td>1.491552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Some</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-26.125000</td>\n",
       "      <td>-26.875000</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>-0.334218</td>\n",
       "      <td>-0.566237</td>\n",
       "      <td>0.566237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chefs</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-28.750000</td>\n",
       "      <td>-29.500000</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>-0.334218</td>\n",
       "      <td>-0.566237</td>\n",
       "      <td>0.566237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-16.875000</td>\n",
       "      <td>-16.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-0.707106</td>\n",
       "      <td>0.707106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humans</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-23.500000</td>\n",
       "      <td>-24.125000</td>\n",
       "      <td>0.535156</td>\n",
       "      <td>0.535156</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>-0.378412</td>\n",
       "      <td>-0.566237</td>\n",
       "      <td>0.566237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-18.000000</td>\n",
       "      <td>-17.875000</td>\n",
       "      <td>1.132812</td>\n",
       "      <td>1.132812</td>\n",
       "      <td>1.132812</td>\n",
       "      <td>-0.801019</td>\n",
       "      <td>-0.801019</td>\n",
       "      <td>0.801019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-11.812500</td>\n",
       "      <td>-11.875000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>-0.662912</td>\n",
       "      <td>-0.662912</td>\n",
       "      <td>0.662912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>-11.500000</td>\n",
       "      <td>0.605469</td>\n",
       "      <td>0.605469</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>-0.428131</td>\n",
       "      <td>-0.566237</td>\n",
       "      <td>0.566237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-12.125000</td>\n",
       "      <td>-12.562500</td>\n",
       "      <td>0.644531</td>\n",
       "      <td>0.644531</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>-0.455752</td>\n",
       "      <td>-0.566237</td>\n",
       "      <td>0.566237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\n</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-0.277344</td>\n",
       "      <td>-0.330078</td>\n",
       "      <td>0.949219</td>\n",
       "      <td>0.949219</td>\n",
       "      <td>0.949219</td>\n",
       "      <td>-0.671198</td>\n",
       "      <td>-0.671198</td>\n",
       "      <td>0.671198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\n</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-12.875000</td>\n",
       "      <td>-13.187500</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>-0.516519</td>\n",
       "      <td>-0.566237</td>\n",
       "      <td>0.566237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hence</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-21.375000</td>\n",
       "      <td>-21.750000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>-0.486135</td>\n",
       "      <td>-0.566237</td>\n",
       "      <td>0.566237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.707106</td>\n",
       "      <td>-15.687500</td>\n",
       "      <td>-15.437500</td>\n",
       "      <td>1.281250</td>\n",
       "      <td>1.281250</td>\n",
       "      <td>1.203125</td>\n",
       "      <td>-0.905980</td>\n",
       "      <td>-0.850737</td>\n",
       "      <td>0.905980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             advantages  old_log_probs  log_probs     ratio  unclipped_ratio  \\\n",
       " that         -0.707106      -9.562500  -9.187500  1.453125         1.453125   \n",
       " some         -0.707106     -15.687500 -16.375000  0.503906         0.503906   \n",
       " chefs        -0.707106     -23.250000 -23.125000  1.132812         1.132812   \n",
       " are          -0.707106     -14.562500 -14.437500  1.132812         1.132812   \n",
       " humans       -0.707106     -17.500000 -17.625000  0.882812         0.882812   \n",
       ".             -0.707106     -13.812500 -14.250000  0.644531         0.644531   \n",
       "\\n            -0.707106      -0.259766  -0.207031  1.054688         1.054688   \n",
       "\\n            -0.707106     -12.375000 -13.125000  0.472656         0.472656   \n",
       "Therefore     -0.707106     -23.875000 -23.750000  1.132812         1.132812   \n",
       ",             -0.707106     -14.687500 -14.312500  1.453125         1.453125   \n",
       " the          -0.707106     -11.437500 -11.687500  0.777344         0.777344   \n",
       " conclusion   -0.707106     -12.125000 -12.250000  0.882812         0.882812   \n",
       " \"            -0.707106     -22.500000 -21.750000  2.109375         2.109375   \n",
       "Some          -0.707106     -26.125000 -26.875000  0.472656         0.472656   \n",
       " chefs        -0.707106     -28.750000 -29.500000  0.472656         0.472656   \n",
       " are          -0.707106     -16.875000 -16.875000  1.000000         1.000000   \n",
       " humans       -0.707106     -23.500000 -24.125000  0.535156         0.535156   \n",
       "\"             -0.707106     -18.000000 -17.875000  1.132812         1.132812   \n",
       " is           -0.707106     -11.812500 -11.875000  0.937500         0.937500   \n",
       " valid        -0.707106     -11.000000 -11.500000  0.605469         0.605469   \n",
       ".             -0.707106     -12.125000 -12.562500  0.644531         0.644531   \n",
       "\\n            -0.707106      -0.277344  -0.330078  0.949219         0.949219   \n",
       "\\n            -0.707106     -12.875000 -13.187500  0.730469         0.730469   \n",
       "Hence         -0.707106     -21.375000 -21.750000  0.687500         0.687500   \n",
       ",             -0.707106     -15.687500 -15.437500  1.281250         1.281250   \n",
       "\n",
       "             clipped_ratio (eps=0.2)  unclipped_loss  clipped_loss (eps=0.2)  \\\n",
       " that                       1.203125       -1.027514               -0.850737   \n",
       " some                       0.800781       -0.356315               -0.566237   \n",
       " chefs                      1.132812       -0.801019               -0.801019   \n",
       " are                        1.132812       -0.801019               -0.801019   \n",
       " humans                     0.882812       -0.624242               -0.624242   \n",
       ".                           0.800781       -0.455752               -0.566237   \n",
       "\\n                          1.054688       -0.745776               -0.745776   \n",
       "\\n                          0.800781       -0.334218               -0.566237   \n",
       "Therefore                   1.132812       -0.801019               -0.801019   \n",
       ",                           1.203125       -1.027514               -0.850737   \n",
       " the                        0.800781       -0.549664               -0.566237   \n",
       " conclusion                 0.882812       -0.624242               -0.624242   \n",
       " \"                          1.203125       -1.491552               -0.850737   \n",
       "Some                        0.800781       -0.334218               -0.566237   \n",
       " chefs                      0.800781       -0.334218               -0.566237   \n",
       " are                        1.000000       -0.707106               -0.707106   \n",
       " humans                     0.800781       -0.378412               -0.566237   \n",
       "\"                           1.132812       -0.801019               -0.801019   \n",
       " is                         0.937500       -0.662912               -0.662912   \n",
       " valid                      0.800781       -0.428131               -0.566237   \n",
       ".                           0.800781       -0.455752               -0.566237   \n",
       "\\n                          0.949219       -0.671198               -0.671198   \n",
       "\\n                          0.800781       -0.516519               -0.566237   \n",
       "Hence                       0.800781       -0.486135               -0.566237   \n",
       ",                           1.203125       -0.905980               -0.850737   \n",
       "\n",
       "                 loss  \n",
       " that        1.027514  \n",
       " some        0.566237  \n",
       " chefs       0.801019  \n",
       " are         0.801019  \n",
       " humans      0.624242  \n",
       ".            0.566237  \n",
       "\\n           0.745776  \n",
       "\\n           0.566237  \n",
       "Therefore    0.801019  \n",
       ",            1.027514  \n",
       " the         0.566237  \n",
       " conclusion  0.624242  \n",
       " \"           1.491552  \n",
       "Some         0.566237  \n",
       " chefs       0.566237  \n",
       " are         0.707106  \n",
       " humans      0.566237  \n",
       "\"            0.801019  \n",
       " is          0.662912  \n",
       " valid       0.566237  \n",
       ".            0.566237  \n",
       "\\n           0.671198  \n",
       "\\n           0.566237  \n",
       "Hence        0.566237  \n",
       ",            0.905980  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df(0, clip_epsilon=0.2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize log probs change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def plot_log_probs(idx):\n",
    "    gap = 4\n",
    "    height = 1\n",
    "    num_tokens = 25\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    tokens = [tokenizer.decode([token]) for token in full_sequence[idx, -num_tokens:]]\n",
    "    plt.barh(\n",
    "        [gap*i for i in range(num_tokens)],\n",
    "        log_probs[idx, -num_tokens:].detach().cpu().float().numpy(),\n",
    "        label=\"log_probs\",\n",
    "        height=height,\n",
    "    )\n",
    "    plt.barh(\n",
    "        [gap*i+1 for i in range(num_tokens)],\n",
    "        old_log_probs[idx, -num_tokens:].detach().cpu().float().numpy(),\n",
    "        label=\"old_log_probs\",\n",
    "        height=height,\n",
    "    )\n",
    "    plt.xlabel(\"log_probs\")\n",
    "    plt.yticks(range(0, gap*num_tokens, gap), reversed(tokens))\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(f\"Advantage: {advantages[idx].item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "idx = 1\n",
    "plot_log_probs(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 2\n",
    "plot_log_probs(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 2\n",
    "plot_log_probs(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 3\n",
    "plot_log_probs(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|im_start|>system\n",
      "\n",
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
      "The assistant first thinks about the reasoning process in the mind and then provides the user\n",
      "with the answer. The reasoning process and answer are enclosed within <think> </think> and\n",
      "<answer> </answer> tags, respectively, i.e., <think> reasoning process here </think>\n",
      "<answer> answer here </answer>.\n",
      "\n",
      "Do not generate new code. Do not write python code.\n",
      "\n",
      "You may also be given examples by the user telling you the expected response format.\n",
      "Follow the format of the examples, but solve the specific problem asked by the user, not the examples.\n",
      "\n",
      "Very important - Remember again, your output format should be:\n",
      "<think> reasoning process here </think>\n",
      "<answer> answer here </answer>\n",
      "\n",
      "Your response will be scored by extracting the substring between the <answer>...</answer> tags.\n",
      "It is critical to follow the above format.\n",
      "feature_extraction_utilsling to follow the response format will result in a penalty.\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "Consider these statements:\n",
      "1. All children are animals\n",
      "2. Some animals are not doctors\n",
      "\n",
      "Does it logically follow that:\n",
      "Some children are not doctors?\n",
      "(Answer Yes or No)<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>From the first premise, \"All children are animals,\" it directly means all children are animals. The second premise tells us that some animals are not doctors. Therefore, the conclusion \"Some children are not doctors\" logically follows from the first premise. Hence, the answer is Yes.</think>\n",
      "<answer> Yes </answer>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(full_sequence[idx], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4142], device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantages[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer...\n",
      "\n",
      "=== MODEL RESPONSES ===\n",
      "\n",
      "Prompt 1:\n",
      "Consider these statements:\n",
      "1. No students are humans\n",
      "2. All humans are chefs\n",
      "\n",
      "Does it logically follow that:\n",
      "Some chefs are humans?\n",
      "(Answer Yes or No)\n",
      "\n",
      "<think> and <answer> Output:\n",
      "there is no overlap between students and humans; \"All humans are chefs\" means all humans (including those who are included in the group of chefs) are also humans. Since no students are humans and all humans are chefs, some individuals who are included in the group of chefs must be human, so the conclusion \"Some chefs are humans\" follows.</think>\n",
      "<answer> Yes }> Yes </answer> crosses the\n",
      "\n",
      " Extracted Answer: Yes }> Yes\n",
      " Expected Answer: Yes\n",
      " Correct\n",
      "\n",
      "Prompt 2:\n",
      "Consider these statements:\n",
      "1. All mammals are warm-blooded.\n",
      "2. Whales are mammals.\n",
      "\n",
      "Does it logically follow that:\n",
      "Whales are warm-blooded?\n",
      "(Answer Yes or No)\n",
      "\n",
      "<think> and <answer> Output:\n",
      "means all mammals (including whales) are warm-blooded. \"Whales are Mating Partners of Mammals\" means there is at least some overlap between mammals and mating partners of whales. Since all mammals belong to the group of warm-blood animals, and whales are part of the group of breeding pairs of mammal males, it follows that whales must be warm-blooded. Therefore, the conclusion \"Warm-\n",
      "\n",
      " Extracted Answer: N/A\n",
      " Expected Answer: Yes\n",
      " Incorrect\n",
      "\n",
      "Prompt 3:\n",
      "Consider these statements:\n",
      "1. All humans are mortal.\n",
      "2. Socrates is a human.\n",
      "\n",
      "Does it logically follow that:\n",
      "Socrates is mortal?\n",
      "(Answer Yes or No)\n",
      "\n",
      "<think> and <answer> Output:\n",
      ".*\" \"Socrates is a *human*.\" \"Socrates is **not** *hospitable*.\") Since all humans are non-mortal (i.e., there exists no overlap with mortals), and Socrates is a human (i.e., there exists at least some overlap with humans), it follows that Socrates must be a part of the group of humans who are not entirely human\n",
      "\n",
      " Extracted Answer: N/A\n",
      " Expected Answer: Yes\n",
      " Incorrect\n",
      "\n",
      "Final Accuracy: 1/3 (33.3%)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import re\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "model_path = \"./saved_model\"  # Path to your trained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Example test prompts and expected answers\n",
    "test_cases = [\n",
    "    {\n",
    "        \"prompt\": \"\"\"Consider these statements:\n",
    "1. No students are humans\n",
    "2. All humans are chefs\n",
    "\n",
    "Does it logically follow that:\n",
    "Some chefs are humans?\n",
    "(Answer Yes or No)\"\"\",\n",
    "        \"expected\": \"Yes\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"\"\"Consider these statements:\n",
    "1. All mammals are warm-blooded.\n",
    "2. Whales are mammals.\n",
    "\n",
    "Does it logically follow that:\n",
    "Whales are warm-blooded?\n",
    "(Answer Yes or No)\"\"\",\n",
    "        \"expected\": \"Yes\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"\"\"Consider these statements:\n",
    "1. All humans are mortal.\n",
    "2. Socrates is a human.\n",
    "\n",
    "Does it logically follow that:\n",
    "Socrates is mortal?\n",
    "(Answer Yes or No)\"\"\",\n",
    "        \"expected\": \"Yes\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# === LOAD MODEL & TOKENIZER ===\n",
    "print(\"Loading model and tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path).to(device)\n",
    "model.eval()\n",
    "\n",
    "# === HELPER FUNCTIONS ===\n",
    "\n",
    "def format_prompt(prompt_text):\n",
    "    \"\"\"Format the prompt to match the model's expected structure.\"\"\"\n",
    "    return f\"\"\"<|im_start|>system\n",
    "A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
    "The assistant first thinks about the reasoning process in the mind and then provides the user\n",
    "with the answer. The reasoning process and answer are enclosed within <think> </think> and\n",
    "<answer> </answer> tags, respectively. Do not generate new code. Do not write python code.\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "{prompt_text}\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "def extract_answer(text):\n",
    "    \"\"\"Extract the content within <answer>...</answer> tags.\"\"\"\n",
    "    match = re.search(r\"<answer>(.*?)</answer>\", text, re.DOTALL)\n",
    "    return match.group(1).strip() if match else \"N/A\"\n",
    "\n",
    "def generate_response(prompt_text):\n",
    "    \"\"\"Run inference and return formatted model output and extracted answer.\"\"\"\n",
    "    full_prompt = format_prompt(prompt_text)\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=False,\n",
    "        num_beams=1,\n",
    "        repetition_penalty=1.2,\n",
    "        length_penalty=0.8,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    # Remove the prompt part to get only the model's answer\n",
    "    response = decoded[len(full_prompt):].strip()\n",
    "    answer = extract_answer(response)\n",
    "    return response, answer\n",
    "\n",
    "# === RUN INFERENCE AND EVALUATE ===\n",
    "correct = 0\n",
    "total = len(test_cases)\n",
    "\n",
    "print(\"\\n=== MODEL RESPONSES ===\\n\")\n",
    "\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    prompt = case[\"prompt\"]\n",
    "    expected = case[\"expected\"]\n",
    "    response, answer = generate_response(prompt)\n",
    "\n",
    "    print(f\"Prompt {i}:\\n{prompt}\\n\")\n",
    "    print(f\"<think> and <answer> Output:\\n{response}\\n\")\n",
    "    print(f\" Extracted Answer: {answer}\")\n",
    "    print(f\" Expected Answer: {expected}\")\n",
    "\n",
    "    if expected.lower() in answer.lower():\n",
    "        print(\" Correct\\n\")\n",
    "        correct += 1\n",
    "    else:\n",
    "        print(\" Incorrect\\n\")\n",
    "\n",
    "print(f\"Final Accuracy: {correct}/{total} ({(100 * correct / total):.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "A conversation between User and Assistant...\n",
      "user\n",
      "Consider these statements:\n",
      "1. All mammals are warm-blooded.\n",
      "2. Whales are mammals.\n",
      "\n",
      "Does it logically follow that:\n",
      "Whales are warm-blooded?\n",
      "(Answer Yes or No)\n",
      "assistant\n",
      "<pre>\n",
      "From the premises:\n",
      "1. All mammals are warm-blooded.\n",
      "2. Whales are mammals.\n",
      "\n",
      "From 2, whales are mammals.\n",
      "\n",
      "Therefore, whales are warm-blooded.\n",
      "\n",
      "Hence, \"Whales are warm-blooded\" is the correct answer.</pre>\n",
      "<ocr>\n",
      "    \"From the premises:\n",
      "       1. All mammals are warm-blooded.\n",
      "       2. Wh whales are mammals.\n",
      "       3. Therefore, whales\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./saved_model\", torch_dtype=torch.bfloat16).to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./saved_model\")\n",
    "\n",
    "prompt = \"\"\"A conversation between User and Assistant...\"\"\"  # same system_prompt\n",
    "\n",
    "question = \"\"\"Consider these statements:\n",
    "1. All mammals are warm-blooded.\n",
    "2. Whales are mammals.\n",
    "\n",
    "Does it logically follow that:\n",
    "Whales are warm-blooded?\n",
    "(Answer Yes or No)\"\"\"\n",
    "\n",
    "# Build input\n",
    "chat_prompt = [\n",
    "    {\"role\": \"system\", \"content\": prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "input_text = tokenizer.apply_chat_template(chat_prompt, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Generate\n",
    "output = model.generate(**inputs, max_new_tokens=100, do_sample=False)\n",
    "decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Truncate at </answer>\n",
    "if \"</answer>\" in decoded:\n",
    "    decoded = decoded.split(\"</answer>\")[0] + \"</answer>\"\n",
    "\n",
    "print(decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GRPO MODEL TESTING\n",
      "============================================================\n",
      "Loading trained model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/athenaik/GRPO_test/.venv/lib/python3.11/site-packages/peft/config.py:165: UserWarning: Unexpected keyword arguments ['qalora_group_size', 'target_parameters', 'use_qalora'] for class LoraConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 9,768,960 || all params: 144,283,968 || trainable%: 6.7706\n",
      " Trained model loaded successfully\n",
      "Loading base model for comparison...\n",
      "trainable params: 9,768,960 || all params: 144,283,968 || trainable%: 6.7706\n",
      " Base model loaded successfully\n",
      "\n",
      "==================================================\n",
      "Testing on dataset: syllogism\n",
      "==================================================\n",
      "\n",
      "Testing trained model...\n",
      "  Processing batch 1...\n",
      "  Processing batch 2...\n",
      "  Processing batch 3...\n",
      "  Processing batch 4...\n",
      "  Processing batch 5...\n",
      "  Processing batch 6...\n",
      "  Processing batch 7...\n",
      "  Processing batch 8...\n",
      "  Processing batch 9...\n",
      "  Processing batch 10...\n",
      "  Processing batch 11...\n",
      "  Processing batch 12...\n",
      "  Processing batch 13...\n",
      "  Processing batch 14...\n",
      "  Processing batch 15...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils import load_peft_model, load_tokenizer, get_dataloader\n",
    "import grpo_utils\n",
    "from reasoning_gym import get_score_answer_fn\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the trained GRPO model on reasoning tasks\n",
    "    \"\"\"\n",
    "    # Config - should match your training config\n",
    "    model_save_path = \"./saved_model\"  # Path where you saved the trained model\n",
    "    base_model_name = \"../SmolLM-135M\"  # Original base model for comparison\n",
    "    test_datasets = [\"syllogism\"]  # Add more datasets as needed\n",
    "    batch_size = 2\n",
    "    max_new_tokens = 100\n",
    "    n_test_samples = 50  # Number of samples to test on\n",
    "    \n",
    "    # Results storage\n",
    "    results = {\n",
    "        \"trained_model\": {},\n",
    "        \"base_model\": {},\n",
    "        \"comparison\": {}\n",
    "    }\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"GRPO MODEL TESTING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load trained model and tokenizer\n",
    "    print(\"Loading trained model...\")\n",
    "    try:\n",
    "        trained_model = load_peft_model(model_save_path)\n",
    "        tokenizer = load_tokenizer(model_save_path)\n",
    "        print(\" Trained model loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error loading trained model: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Load base model for comparison\n",
    "    print(\"Loading base model for comparison...\")\n",
    "    try:\n",
    "        base_model = load_peft_model(base_model_name)\n",
    "        base_tokenizer = load_tokenizer(base_model_name)\n",
    "        print(\" Base model loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error loading base model: {e}\")\n",
    "        base_model = None\n",
    "    \n",
    "    # Test on each dataset\n",
    "    for dataset_name in test_datasets:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Testing on dataset: {dataset_name}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Get test dataloader\n",
    "        test_dataloader = get_dataloader(dataset_name, tokenizer, batch_size=batch_size)\n",
    "        \n",
    "        # Test trained model\n",
    "        print(\"\\nTesting trained model...\")\n",
    "        trained_results = evaluate_model(\n",
    "            trained_model, tokenizer, test_dataloader, \n",
    "            max_new_tokens, n_test_samples, \"Trained Model\"\n",
    "        )\n",
    "        results[\"trained_model\"][dataset_name] = trained_results\n",
    "        \n",
    "        # Test base model if available\n",
    "        if base_model is not None:\n",
    "            print(\"\\nTesting base model...\")\n",
    "            base_results = evaluate_model(\n",
    "                base_model, base_tokenizer, test_dataloader, \n",
    "                max_new_tokens, n_test_samples, \"Base Model\"\n",
    "            )\n",
    "            results[\"base_model\"][dataset_name] = base_results\n",
    "            \n",
    "            # Compare results\n",
    "            comparison = compare_models(trained_results, base_results, dataset_name)\n",
    "            results[\"comparison\"][dataset_name] = comparison\n",
    "    \n",
    "    # Save results\n",
    "    save_results(results)\n",
    "    \n",
    "    # Generate plots\n",
    "    if results[\"base_model\"]:\n",
    "        plot_comparison(results)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"TESTING COMPLETED\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "def evaluate_model(model, tokenizer, dataloader, max_new_tokens, n_samples, model_name):\n",
    "    \"\"\"\n",
    "    Evaluate a model on the given dataloader\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Metrics storage\n",
    "    format_rewards = []\n",
    "    correctness_rewards = []\n",
    "    total_rewards = []\n",
    "    response_lengths = []\n",
    "    samples_processed = 0\n",
    "    sample_responses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            if samples_processed >= n_samples:\n",
    "                break\n",
    "                \n",
    "            input_ids = batch[\"inputs\"][\"input_ids\"]\n",
    "            attention_mask = batch[\"inputs\"][\"attention_mask\"]\n",
    "            validators = batch[\"validator\"]\n",
    "            \n",
    "            print(f\"  Processing batch {batch_idx + 1}...\")\n",
    "            \n",
    "            # Generate responses\n",
    "            try:\n",
    "                full_responses = model.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                    do_sample=True,\n",
    "                    top_p=0.95,\n",
    "                    temperature=0.7,  # Lower temperature for testing\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    pad_token_id=tokenizer.eos_token_id,\n",
    "                )\n",
    "                \n",
    "                # Extract only the generated part\n",
    "                input_size = input_ids.shape[1]\n",
    "                assistant_responses = full_responses[:, input_size:]\n",
    "                \n",
    "                # Decode responses\n",
    "                decoded_responses = tokenizer.batch_decode(\n",
    "                    assistant_responses, skip_special_tokens=True\n",
    "                )\n",
    "                \n",
    "                # Calculate rewards for each response\n",
    "                for i, (response, validator) in enumerate(zip(decoded_responses, validators)):\n",
    "                    # Format reward\n",
    "                    format_reward = grpo_utils.calculate_format_reward(response)\n",
    "                    format_rewards.append(format_reward)\n",
    "                    \n",
    "                    # Correctness reward\n",
    "                    extracted_answer = grpo_utils.extract_answer(response)\n",
    "                    correctness_reward = grpo_utils.calculate_correctness_reward(response, validator)\n",
    "                    correctness_rewards.append(correctness_reward)\n",
    "                    \n",
    "                    # Total reward\n",
    "                    total_reward = (grpo_utils.FORMAT_REWARD_WEIGHT * format_reward + \n",
    "                                  grpo_utils.CORRECTNESS_REWARD_WEIGHT * correctness_reward)\n",
    "                    total_rewards.append(total_reward)\n",
    "                    \n",
    "                    # Response length\n",
    "                    response_lengths.append(len(response.split()))\n",
    "                    \n",
    "                    # Store sample for inspection\n",
    "                    if len(sample_responses) < 5:  # Store first 5 samples\n",
    "                        sample_responses.append({\n",
    "                            \"question\": validator[\"question\"],\n",
    "                            \"response\": response,\n",
    "                            \"extracted_answer\": extracted_answer,\n",
    "                            \"expected\": validator.get(\"answer\", \"N/A\"),\n",
    "                            \"format_reward\": format_reward,\n",
    "                            \"correctness_reward\": correctness_reward,\n",
    "                            \"total_reward\": total_reward\n",
    "                        })\n",
    "                    \n",
    "                    samples_processed += 1\n",
    "                    if samples_processed >= n_samples:\n",
    "                        break\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"    Error in batch {batch_idx + 1}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Calculate statistics\n",
    "    results = {\n",
    "        \"model_name\": model_name,\n",
    "        \"samples_processed\": samples_processed,\n",
    "        \"avg_format_reward\": np.mean(format_rewards),\n",
    "        \"avg_correctness_reward\": np.mean(correctness_rewards), \n",
    "        \"avg_total_reward\": np.mean(total_rewards),\n",
    "        \"accuracy\": np.mean([r > 0.5 for r in correctness_rewards]),\n",
    "        \"format_compliance\": np.mean([r > 0.5 for r in format_rewards]),\n",
    "        \"avg_response_length\": np.mean(response_lengths),\n",
    "        \"std_total_reward\": np.std(total_rewards),\n",
    "        \"sample_responses\": sample_responses,\n",
    "        \"all_rewards\": {\n",
    "            \"format\": format_rewards,\n",
    "            \"correctness\": correctness_rewards,\n",
    "            \"total\": total_rewards\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n  Results for {model_name}:\")\n",
    "    print(f\"    Samples processed: {samples_processed}\")\n",
    "    print(f\"    Average total reward: {results['avg_total_reward']:.4f}  {results['std_total_reward']:.4f}\")\n",
    "    print(f\"    Accuracy: {results['accuracy']:.2%}\")\n",
    "    print(f\"    Format compliance: {results['format_compliance']:.2%}\")\n",
    "    print(f\"    Avg response length: {results['avg_response_length']:.1f} words\")\n",
    "    print(f\"    Format reward: {results['avg_format_reward']:.4f}\")\n",
    "    print(f\"    Correctness reward: {results['avg_correctness_reward']:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def compare_models(trained_results, base_results, dataset_name):\n",
    "    \"\"\"\n",
    "    Compare trained model vs base model results\n",
    "    \"\"\"\n",
    "    print(f\"\\n  Comparison for {dataset_name}:\")\n",
    "    \n",
    "    improvements = {\n",
    "        \"total_reward\": trained_results['avg_total_reward'] - base_results['avg_total_reward'],\n",
    "        \"accuracy\": trained_results['accuracy'] - base_results['accuracy'],\n",
    "        \"format_compliance\": trained_results['format_compliance'] - base_results['format_compliance'],\n",
    "    }\n",
    "    \n",
    "    print(f\"    Total reward improvement: {improvements['total_reward']:+.4f}\")\n",
    "    print(f\"    Accuracy improvement: {improvements['accuracy']:+.2%}\")\n",
    "    print(f\"    Format compliance improvement: {improvements['format_compliance']:+.2%}\")\n",
    "    \n",
    "    return improvements\n",
    "\n",
    "def save_results(results):\n",
    "    \"\"\"\n",
    "    Save results to JSON file\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"test_results_{timestamp}.json\"\n",
    "    \n",
    "    # Convert numpy arrays to lists for JSON serialization\n",
    "    json_results = {}\n",
    "    for model_type, model_results in results.items():\n",
    "        json_results[model_type] = {}\n",
    "        for dataset, dataset_results in model_results.items():\n",
    "            json_results[model_type][dataset] = {}\n",
    "            for key, value in dataset_results.items():\n",
    "                if isinstance(value, np.ndarray):\n",
    "                    json_results[model_type][dataset][key] = value.tolist()\n",
    "                elif isinstance(value, dict) and \"all_rewards\" in key:\n",
    "                    json_results[model_type][dataset][key] = {\n",
    "                        k: v.tolist() if isinstance(v, list) else v \n",
    "                        for k, v in value.items()\n",
    "                    }\n",
    "                else:\n",
    "                    json_results[model_type][dataset][key] = value\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(json_results, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"\\nResults saved to: {filename}\")\n",
    "\n",
    "def plot_comparison(results):\n",
    "    \"\"\"\n",
    "    Create comparison plots\n",
    "    \"\"\"\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('GRPO Training Results Comparison', fontsize=16)\n",
    "    \n",
    "    for dataset_name in results[\"trained_model\"].keys():\n",
    "        trained = results[\"trained_model\"][dataset_name]\n",
    "        base = results[\"base_model\"][dataset_name]\n",
    "        \n",
    "        # Plot 1: Reward comparison\n",
    "        ax1 = axes[0, 0]\n",
    "        categories = ['Total Reward', 'Accuracy', 'Format Compliance']\n",
    "        trained_values = [trained['avg_total_reward'], trained['accuracy'], trained['format_compliance']]\n",
    "        base_values = [base['avg_total_reward'], base['accuracy'], base['format_compliance']]\n",
    "        \n",
    "        x = np.arange(len(categories))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax1.bar(x - width/2, base_values, width, label='Base Model', alpha=0.7)\n",
    "        ax1.bar(x + width/2, trained_values, width, label='Trained Model', alpha=0.7)\n",
    "        ax1.set_xlabel('Metrics')\n",
    "        ax1.set_ylabel('Score')\n",
    "        ax1.set_title('Performance Comparison')\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(categories)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Plot 2: Reward distribution\n",
    "        ax2 = axes[0, 1]\n",
    "        ax2.hist(trained['all_rewards']['total'], alpha=0.7, label='Trained Model', bins=20)\n",
    "        ax2.hist(base['all_rewards']['total'], alpha=0.7, label='Base Model', bins=20)\n",
    "        ax2.set_xlabel('Total Reward')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        ax2.set_title('Reward Distribution')\n",
    "        ax2.legend()\n",
    "        \n",
    "        # Plot 3: Sample responses comparison (first few)\n",
    "        ax3 = axes[1, 0]\n",
    "        sample_trained_rewards = [s['total_reward'] for s in trained['sample_responses'][:10]]\n",
    "        sample_base_rewards = [s['total_reward'] for s in base['sample_responses'][:10]]\n",
    "        \n",
    "        x = range(len(sample_trained_rewards))\n",
    "        ax3.plot(x, sample_trained_rewards, 'o-', label='Trained Model')\n",
    "        ax3.plot(x, sample_base_rewards, 's-', label='Base Model')\n",
    "        ax3.set_xlabel('Sample Index')\n",
    "        ax3.set_ylabel('Total Reward')\n",
    "        ax3.set_title('Sample-by-Sample Comparison')\n",
    "        ax3.legend()\n",
    "        \n",
    "        # Plot 4: Improvements\n",
    "        ax4 = axes[1, 1]\n",
    "        comparison = results[\"comparison\"][dataset_name]\n",
    "        improvements = list(comparison.values())\n",
    "        improvement_names = list(comparison.keys())\n",
    "        \n",
    "        colors = ['green' if x > 0 else 'red' for x in improvements]\n",
    "        ax4.bar(improvement_names, improvements, color=colors, alpha=0.7)\n",
    "        ax4.set_ylabel('Improvement')\n",
    "        ax4.set_title('Training Improvements')\n",
    "        ax4.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        plt.setp(ax4.get_xticklabels(), rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    plt.savefig(f'grpo_comparison_{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Comparison plots saved as: grpo_comparison_{timestamp}.png\")\n",
    "\n",
    "def inspect_sample_responses(results):\n",
    "    \"\"\"\n",
    "    Print detailed inspection of sample responses\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"SAMPLE RESPONSE INSPECTION\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for model_type in [\"base_model\", \"trained_model\"]:\n",
    "        if model_type not in results or not results[model_type]:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{model_type.replace('_', ' ').title()}:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for dataset_name, dataset_results in results[model_type].items():\n",
    "            print(f\"\\nDataset: {dataset_name}\")\n",
    "            \n",
    "            for i, sample in enumerate(dataset_results[\"sample_responses\"][:3]):\n",
    "                print(f\"\\n  Sample {i+1}:\")\n",
    "                print(f\"    Question: {sample['question'][:100]}...\")\n",
    "                print(f\"    Response: {sample['response'][:200]}...\")\n",
    "                print(f\"    Extracted Answer: {sample['extracted_answer']}\")\n",
    "                print(f\"    Expected: {sample['expected']}\")\n",
    "                print(f\"    Rewards - Format: {sample['format_reward']:.3f}, \"\n",
    "                      f\"Correctness: {sample['correctness_reward']:.3f}, \"\n",
    "                      f\"Total: {sample['total_reward']:.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the test\n",
    "    test_model()\n",
    "    \n",
    "    # Optional: Load and inspect previous results\n",
    "    # results_file = \"test_results_20240101_120000.json\"  # Replace with actual filename\n",
    "    # if os.path.exists(results_file):\n",
    "    #     with open(results_file, 'r') as f:\n",
    "    #         loaded_results = json.load(f)\n",
    "    #     inspect_sample_responses(loaded_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/athenaik/GRPO_test/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/athenaik/GRPO_test/.venv/lib/python3.11/site-packages/peft/config.py:165: UserWarning: Unexpected keyword arguments ['qalora_group_size', 'target_parameters', 'use_qalora'] for class LoraConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 9,768,960 || all params: 144,283,968 || trainable%: 6.7706\n",
      " Model loaded successfully\n",
      "\n",
      "================================================================================\n",
      "TESTING MODEL WITH SAMPLE QUESTIONS\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "QUESTION 1:\n",
      "============================================================\n",
      "Q: All birds can fly. Penguins are birds. Can penguins fly?\n",
      "Expected: No (penguins cannot fly despite being birds)\n",
      "------------------------------------------------------------\n",
      "MODEL OUTPUT:\n",
      "<think>\n",
      "From the premises:\n",
      "\n",
      "* All birds can fly.\n",
      "* Penguins are birds.\n",
      "* Can penguins fly.\n",
      "\n",
      "The conclusion \"All birds can fly\" means all birds can fly.\n",
      "\n",
      "Therefore, all birds can fly.\n",
      "\n",
      "**Answer:** (C)</answer>\n",
      "<answer> C > C </answer> catarata>\n",
      "<context>The given premises are true, but the conclusion \"All birds can fly\" means all birds can fly. Therefore, the correct answer is C)</answer>\n",
      "<context>The given conclusion \"All birds can fly\" means all birds can fly.</answer>\n",
      "------------------------------------------------------------\n",
      "ANALYSIS:\n",
      "  Extracted Answer: 'C > C'\n",
      "  Format Reward: 0.85 (1.0 = perfect format)\n",
      "  Has <think> tags: \n",
      "  Has <answer> tags: \n",
      "  Answer Length: 5 characters\n",
      "\n",
      "============================================================\n",
      "QUESTION 2:\n",
      "============================================================\n",
      "Q: If all roses are flowers, and some flowers are red, then some roses are red. Is this statement logically valid?\n",
      "Expected: No (the conclusion doesn't logically follow)\n",
      "------------------------------------------------------------\n",
      "MODEL OUTPUT:\n",
      "<think>\n",
      "From the premises:\n",
      "\n",
      "All roses are flowers.\n",
      "Some flowers are red.\n",
      "All roses are red.\n",
      "\n",
      "From these, it follows that all roses are red.\n",
      "\n",
      "Therefore, the statement \"Some roses are red\" is valid.\n",
      "</think>\n",
      "<answer> Yes </answer> crocodiles.com>\n",
      "< concluder>Yes </ concluder>\n",
      "------------------------------------------------------------\n",
      "ANALYSIS:\n",
      "  Extracted Answer: 'Yes'\n",
      "  Format Reward: 1.00 (1.0 = perfect format)\n",
      "  Has <think> tags: \n",
      "  Has <answer> tags: \n",
      "  Answer Length: 3 characters\n",
      "\n",
      "============================================================\n",
      "QUESTION 3:\n",
      "============================================================\n",
      "Q: All cats are mammals. Some mammals are dogs. Therefore, some cats are dogs. Is this reasoning correct?\n",
      "Expected: No (the reasoning is invalid)\n",
      "------------------------------------------------------------\n",
      "MODEL OUTPUT:\n",
      "<think>From the premises: All cats are mammals, Some mammals are dogs, And some cats are dogs. Since all cats are mammals, and some mammals are dogs, it means some cats are dogs. Therefore, some cats are dogs. The conclusion \"All cats are dogs\" is correct.</think>\n",
      "<answer> Yes </answer> deepcopy>\n",
      "```\n",
      "<think>From the premises: All cats are mammals, Some mammals are dogs, And some cats are dogs. Since all cats are mammals, and some mammals are dogs, it means some cats are dogs. Therefore, some cats are dogs. The conclusion \"All cats are dogs\" is correct.</think>\n",
      "<answer> Yes </answer> deepcopy>\n",
      "\n",
      "------------------------------------------------------------\n",
      "ANALYSIS:\n",
      "  Extracted Answer: 'Yes'\n",
      "  Format Reward: 1.00 (1.0 = perfect format)\n",
      "  Has <think> tags: \n",
      "  Has <answer> tags: \n",
      "  Answer Length: 3 characters\n",
      "\n",
      "================================================================================\n",
      "TESTING COMPLETED\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils import load_peft_model, load_tokenizer\n",
    "import grpo_utils\n",
    "\n",
    "def test_model_with_questions():\n",
    "    \"\"\"\n",
    "    Simple test: Pass some questions and see what the model outputs\n",
    "    \"\"\"\n",
    "    # Load your trained model\n",
    "    model_save_path = \"./saved_model\"\n",
    "    \n",
    "    print(\"Loading trained model...\")\n",
    "    try:\n",
    "        model = load_peft_model(model_save_path)\n",
    "        tokenizer = load_tokenizer(model_save_path)\n",
    "        print(\" Model loaded successfully\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error loading model: {e}\")\n",
    "        return\n",
    "    \n",
    "    # System prompt (same as training)\n",
    "    system_prompt = \"\"\"\n",
    "A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
    "The assistant first thinks about the reasoning process in the mind and then provides the user\n",
    "with the answer. The reasoning process and answer are enclosed within <think> </think> and\n",
    "<answer> </answer> tags, respectively, i.e., <think> reasoning process here </think>\n",
    "<answer> answer here </answer>.\n",
    "\n",
    "Do not generate new code. Do not write python code.\n",
    "\n",
    "You may also be given examples by the user telling you the expected response format.\n",
    "Follow the format of the examples, but solve the specific problem asked by the user, not the examples.\n",
    "\n",
    "Very important - Remember again, your output format should be:\n",
    "<think> reasoning process here </think>\n",
    "<answer> answer here </answer>\n",
    "\n",
    "Your response will be scored by extracting the substring between the <answer>...</answer> tags.\n",
    "It is critical to follow the response format will result in a penalty.\n",
    "\"\"\"\n",
    "\n",
    "    # Test questions - you can modify these\n",
    "    test_questions = [\n",
    "        \"All birds can fly. Penguins are birds. Can penguins fly?\",\n",
    "        \n",
    "        \"If all roses are flowers, and some flowers are red, then some roses are red. Is this statement logically valid?\",\n",
    "        \n",
    "        \"All cats are mammals. Some mammals are dogs. Therefore, some cats are dogs. Is this reasoning correct?\"\n",
    "    ]\n",
    "    \n",
    "    expected_answers = [\n",
    "        \"No (penguins cannot fly despite being birds)\",\n",
    "        \"No (the conclusion doesn't logically follow)\",\n",
    "        \"No (the reasoning is invalid)\"\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"TESTING MODEL WITH SAMPLE QUESTIONS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (question, expected) in enumerate(zip(test_questions, expected_answers)):\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"QUESTION {i+1}:\")\n",
    "            print(f\"{'='*60}\")\n",
    "            print(f\"Q: {question}\")\n",
    "            print(f\"Expected: {expected}\")\n",
    "            print(f\"{'-'*60}\")\n",
    "            \n",
    "            # Create the prompt\n",
    "            chat_prompt = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ]\n",
    "            \n",
    "            # Tokenize\n",
    "            prompt_text = tokenizer.apply_chat_template(\n",
    "                chat_prompt, tokenize=False, add_generation_prompt=True\n",
    "            )\n",
    "            \n",
    "            inputs = tokenizer(prompt_text, return_tensors=\"pt\")\n",
    "            input_ids = inputs[\"input_ids\"].to(model.device)\n",
    "            attention_mask = inputs[\"attention_mask\"].to(model.device)\n",
    "            \n",
    "            # Generate response\n",
    "            try:\n",
    "                output = model.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    max_new_tokens=150,\n",
    "                    do_sample=True,\n",
    "                    top_p=0.95,\n",
    "                    temperature=0.7,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    pad_token_id=tokenizer.eos_token_id,\n",
    "                )\n",
    "                \n",
    "                # Decode only the generated part\n",
    "                input_length = input_ids.shape[1]\n",
    "                generated_tokens = output[0][input_length:]\n",
    "                response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "                \n",
    "                print(\"MODEL OUTPUT:\")\n",
    "                print(response)\n",
    "                print(f\"{'-'*60}\")\n",
    "                \n",
    "                # Extract and evaluate the answer\n",
    "                extracted_answer = grpo_utils.extract_answer(response)\n",
    "                format_reward = grpo_utils.calculate_format_reward(response)\n",
    "                \n",
    "                print(\"ANALYSIS:\")\n",
    "                print(f\"  Extracted Answer: '{extracted_answer}'\")\n",
    "                print(f\"  Format Reward: {format_reward:.2f} (1.0 = perfect format)\")\n",
    "                print(f\"  Has <think> tags: {'' if '<think>' in response else ''}\")\n",
    "                print(f\"  Has <answer> tags: {'' if '<answer>' in response and '</answer>' in response else ''}\")\n",
    "                \n",
    "                # Simple correctness check\n",
    "                if extracted_answer.lower().strip():\n",
    "                    print(f\"  Answer Length: {len(extracted_answer)} characters\")\n",
    "                else:\n",
    "                    print(f\"    No answer extracted!\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\" Error generating response: {e}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"TESTING COMPLETED\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "def test_custom_questions():\n",
    "    \"\"\"\n",
    "    Let user input their own questions\n",
    "    \"\"\"\n",
    "    # Load your trained model\n",
    "    model_save_path = \"./saved_model\"\n",
    "    \n",
    "    print(\"Loading trained model...\")\n",
    "    try:\n",
    "        model = load_peft_model(model_save_path)\n",
    "        tokenizer = load_tokenizer(model_save_path)\n",
    "        print(\" Model loaded successfully\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error loading model: {e}\")\n",
    "        return\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
    "The assistant first thinks about the reasoning process in the mind and then provides the user\n",
    "with the answer. The reasoning process and answer are enclosed within <think> </think> and\n",
    "<answer> </answer> tags, respectively, i.e., <think> reasoning process here </think>\n",
    "<answer> answer here </answer>.\n",
    "\n",
    "Do not generate new code. Do not write python code.\n",
    "\n",
    "Very important - Remember again, your output format should be:\n",
    "<think> reasoning process here </think>\n",
    "<answer> answer here </answer>\n",
    "\n",
    "Your response will be scored by extracting the substring between the <answer>...</answer> tags.\n",
    "It is critical to follow the response format will result in a penalty.\n",
    "\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    print(\"Enter your questions (type 'quit' to exit):\")\n",
    "    \n",
    "    while True:\n",
    "        question = input(\"\\nYour question: \").strip()\n",
    "        \n",
    "        if question.lower() in ['quit', 'exit', 'q']:\n",
    "            break\n",
    "            \n",
    "        if not question:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{'-'*50}\")\n",
    "        print(\"MODEL RESPONSE:\")\n",
    "        print(f\"{'-'*50}\")\n",
    "        \n",
    "        # Create the prompt\n",
    "        chat_prompt = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ]\n",
    "        \n",
    "        prompt_text = tokenizer.apply_chat_template(\n",
    "            chat_prompt, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        \n",
    "        inputs = tokenizer(prompt_text, return_tensors=\"pt\")\n",
    "        input_ids = inputs[\"input_ids\"].to(model.device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                output = model.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    max_new_tokens=150,\n",
    "                    do_sample=True,\n",
    "                    top_p=0.95,\n",
    "                    temperature=0.7,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    pad_token_id=tokenizer.eos_token_id,\n",
    "                )\n",
    "                \n",
    "                input_length = input_ids.shape[1]\n",
    "                generated_tokens = output[0][input_length:]\n",
    "                response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "                \n",
    "                print(response)\n",
    "                \n",
    "                # Quick analysis\n",
    "                extracted_answer = grpo_utils.extract_answer(response)\n",
    "                format_reward = grpo_utils.calculate_format_reward(response)\n",
    "                \n",
    "                print(f\"\\nQuick Analysis:\")\n",
    "                print(f\"  Extracted Answer: '{extracted_answer}'\")\n",
    "                print(f\"  Format Score: {format_reward:.2f}/1.0\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with predefined questions\n",
    "    test_model_with_questions()\n",
    "    \n",
    "    # Uncomment below if you want interactive testing\n",
    "    # print(\"\\n\" + \"=\"*60)\n",
    "    # print(\"INTERACTIVE TESTING\")\n",
    "    # print(\"=\"*60)\n",
    "    # test_custom_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/athenaik/GRPO_test/.venv/lib/python3.11/site-packages/peft/config.py:165: UserWarning: Unexpected keyword arguments ['qalora_group_size', 'target_parameters', 'use_qalora'] for class LoraConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n",
      "  warnings.warn(\n",
      "/home/athenaik/GRPO_test/.venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/athenaik/GRPO_test/.venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prompt:\n",
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
      "The assistant first thinks about the reasoning process in the mind and then provides the user\n",
      "with the answer. The reasoning process and answer are enclosed within <think> </think> and\n",
      "<answer> </answer> tags, respectively.\n",
      "\n",
      "Do not generate new code. Do not write python code.\n",
      "\n",
      "Your response must follow the format:\n",
      "\n",
      "<think> reasoning here </think>\n",
      "<answer> answer here </answer>\n",
      "\n",
      "---\n",
      "\n",
      "User: \n",
      "Consider these statements:\n",
      "1. All children are animals\n",
      "2. Some animals are not doctors\n",
      "\n",
      "Does it logically follow that:\n",
      "Some children are not doctors?\n",
      "(Answer Yes or No)\n",
      "Assistant:\n",
      "\n",
      "\n",
      " Full Output:\n",
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
      "The assistant first thinks about the reasoning process in the mind and then provides the user\n",
      "with the answer. The reasoning process and answer are enclosed within <think> </think> and\n",
      "<answer> </answer> tags, respectively.\n",
      "\n",
      "Do not generate new code. Do not write python code.\n",
      "\n",
      "Your response must follow the format:\n",
      "\n",
      "<think> reasoning here </think>\n",
      "<answer> answer here </answer>\n",
      "\n",
      "---\n",
      "\n",
      "User: \n",
      "Consider these statements:\n",
      "1. All children are animals\n",
      "2. Some animals are not doctors\n",
      "\n",
      "Does it logically follow that:\n",
      "Some children are not doctors?\n",
      "(Answer Yes or No)\n",
      "Assistant:\n",
      "<answer> Yes </ assembl>\n",
      "<answer> Yes </ assembl>\n",
      "</g>\n",
      "<g>Yes </ assembl> catar>**The Mysterious Case of the Missing Pizza**\n",
      "\n",
      "It was a typical Tuesday evening in the small town of Willow Creek. The residents were enjoying a late-night pizza joint, and the local diner was bustling with customers. Amidst the chaos, a group of friends, all in their early twenties, were gathered at the corner, discussing the latest gossip.\n",
      "\n",
      "\"I don't think anyone has found the last pizza,\" said Emily, a history buff. \"The one that was last seen at the corner.\"\n",
      "\n",
      "\"No, no, no,\" said Jake, a\n",
      "\n",
      " Extracted <think> and <answer>:\n",
      " <think> tag not found\n",
      " <answer> tag not found\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import re\n",
    "\n",
    "def extract_tags(text):\n",
    "    think = re.search(r\"<think>(.*?)</think>\", text, re.DOTALL)\n",
    "    answer = re.search(r\"<answer>(.*?)</answer>\", text, re.DOTALL)\n",
    "    return (think.group(1).strip() if think else None, answer.group(1).strip() if answer else None)\n",
    "\n",
    "def test_single_prompt():\n",
    "    model_path = \"./saved_model\"\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Question to test\n",
    "    prompt = \"\"\"A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
    "The assistant first thinks about the reasoning process in the mind and then provides the user\n",
    "with the answer. The reasoning process and answer are enclosed within <think> </think> and\n",
    "<answer> </answer> tags, respectively.\n",
    "\n",
    "Do not generate new code. Do not write python code.\n",
    "\n",
    "Your response must follow the format:\n",
    "\n",
    "<think> reasoning here </think>\n",
    "<answer> answer here </answer>\n",
    "\n",
    "---\n",
    "\n",
    "User: \n",
    "Consider these statements:\n",
    "1. All children are animals\n",
    "2. Some animals are not doctors\n",
    "\n",
    "Does it logically follow that:\n",
    "Some children are not doctors?\n",
    "(Answer Yes or No)\n",
    "Assistant:\n",
    "\"\"\"\n",
    "\n",
    "    # Encode\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=150,\n",
    "            do_sample=False,\n",
    "            top_p=0.9,\n",
    "            temperature=0.3,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    full_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract tags\n",
    "    think, answer = extract_tags(full_output)\n",
    "\n",
    "    print(\"\\n Prompt:\")\n",
    "    print(prompt)\n",
    "    print(\"\\n Full Output:\")\n",
    "    print(full_output)\n",
    "    print(\"\\n Extracted <think> and <answer>:\")\n",
    "    print(f\"<think> {think} </think>\" if think else \" <think> tag not found\")\n",
    "    print(f\"<answer> {answer} </answer>\" if answer else \" <answer> tag not found\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_single_prompt()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 9,768,960 || all params: 144,283,968 || trainable%: 6.7706\n"
     ]
    }
   ],
   "source": [
    "from utils import load_peft_model, load_tokenizer, get_dataloader, left_pad\n",
    "model_name = \"../SmolLM-135M\"\n",
    "llm = load_peft_model(model_name)  # full finetuning\n",
    "tokenizer = load_tokenizer(model_name)\n",
    "dataloader = get_dataloader(\"syllogism\", tokenizer, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type: <class 'dict'>\n",
      "Batch keys: dict_keys(['validator', 'inputs'])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(\"Batch type:\", type(batch))\n",
    "    if isinstance(batch, dict):\n",
    "        print(\"Batch keys:\", batch.keys())\n",
    "    elif isinstance(batch, (tuple, list)):\n",
    "        print(\"Batch length:\", len(batch))\n",
    "        print(\"Element 0 type:\", type(batch[0]))\n",
    "    else:\n",
    "        print(\"Unknown batch format:\", batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of inputs: <class 'dict'>\n",
      "Keys in inputs: dict_keys(['input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    inputs = batch['inputs']\n",
    "    print(\"Type of inputs:\", type(inputs))\n",
    "    \n",
    "    if isinstance(inputs, dict):\n",
    "        print(\"Keys in inputs:\", inputs.keys())\n",
    "    elif isinstance(inputs, (list, tuple)):\n",
    "        print(\"Sample input:\", inputs[0])\n",
    "    else:\n",
    "        print(\"Inputs content:\", inputs)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "Input IDs: tensor([    2,     2,     1,  9690,   198,   198,    49,  6634,   826, 11122,\n",
      "          284, 20108,    30,   378,  2914, 11421,   253,  1962,    28,   284,\n",
      "          260, 20108, 35242,   357,    30,   198,   504, 11173,   808, 12528,\n",
      "          563,   260, 10115,   980,   281,   260,  1945,   284,   965,  2433,\n",
      "          260,  2914,   198,  3659,   260,  2988,    30,   378, 10115,   980,\n",
      "          284,  2988,   359, 20657,  1127,  2067, 17400,    46, 22577, 17400,\n",
      "           46,   284,   198,    44, 11247,    46, 22577, 11247,    46, 12082,\n",
      "           28,  7827,    28,  2056,    30,    85,  1143,  2067, 17400,    46,\n",
      "        10115,   980,  1535, 22577, 17400,    46,   198,    44, 11247,    46,\n",
      "         2988,  1535, 22577, 11247, 19369,   198,   198,  6248,   441,  5051,\n",
      "          725,  2909,    30,  3315,   441,  2965, 11129,  2909,    30,   198,\n",
      "          198,  2683,   654,   597,   325,  1836,  3480,   411,   260,  2914,\n",
      "         8932,   346,   260,  3393,  2426,  4624,    30,   198, 11101,   260,\n",
      "         4624,   282,   260,  3480,    28,   564,  5482,   260,  1678,  1732,\n",
      "         3413,   411,   260,  2914,    28,   441,   260,  3480,    30,   198,\n",
      "          198, 26111,  1070,   731,  5258,  1163,    28,   469,  3124,  4624,\n",
      "          868,   325,    42,   198,    44, 17400,    46, 10115,   980,  1535,\n",
      "        22577, 17400,    46,   198,    44, 11247,    46,  2988,  1535, 22577,\n",
      "        11247,    46,   198,   198,  7334,  2426,   523,   325, 22440,   411,\n",
      "        28042,   260,   840,  5931,   826,   260,  2067, 11247,    46,  2026,\n",
      "         9617, 11247,    46, 12082,    30,   198,  1589,   314,  2609,   288,\n",
      "         1066,   260,  2120,  4624,    30,   198, 12839,    79,  1527,  4550,\n",
      "           79,  7638,  1519,   288,  1066,   260,  2426,  4624,   523,   966,\n",
      "          281,   253, 15919,    30,   198,     2,   198,     1,  4093,   198,\n",
      "        16865,   623,  7868,    42,   198,    33,    30,  2838,  1058,   359,\n",
      "         2973,   198,    34,    30,  2018,  2973,   359, 22350,   198,   198,\n",
      "        14748,   357, 27177,  1066,   338,    42,   198,  4449, 22350,   359,\n",
      "         2973,    47,   198,    24, 21350,  9230,   355,  2838,    25,     2,\n",
      "          198,     1,   520,  9531,   198])\n",
      "Decoded Input: system\n",
      "\n",
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
      "The assistant first thinks about the reasoning process in the mind and then provides the user\n",
      "with the answer. The reasoning process and answer are enclosed within <think> </think> and\n",
      "<answer> </answer> tags, respectively, i.e., <think> reasoning process here </think>\n",
      "<answer> answer here </answer>.\n",
      "\n",
      "Do not generate new code. Do not write python code.\n",
      "\n",
      "You may also be given examples by the user telling you the expected response format.\n",
      "Follow the format of the examples, but solve the specific problem asked by the user, not the examples.\n",
      "\n",
      "Very important - Remember again, your output format should be:\n",
      "<think> reasoning process here </think>\n",
      "<answer> answer here </answer>\n",
      "\n",
      "Your response will be scored by extracting the substring between the <answer>...</answer> tags.\n",
      "It is critical to follow the above format.\n",
      "feature_extraction_utilsling to follow the response format will result in a penalty.\n",
      "\n",
      "user\n",
      "Consider these statements:\n",
      "1. No students are humans\n",
      "2. All humans are chefs\n",
      "\n",
      "Does it logically follow that:\n",
      "Some chefs are humans?\n",
      "(Answer Yes or No)\n",
      "assistant\n",
      "\n",
      "--------------------------------------------------\n",
      "Sample 2:\n",
      "Input IDs: tensor([    1,  9690,   198,   198,    49,  6634,   826, 11122,   284, 20108,\n",
      "           30,   378,  2914, 11421,   253,  1962,    28,   284,   260, 20108,\n",
      "        35242,   357,    30,   198,   504, 11173,   808, 12528,   563,   260,\n",
      "        10115,   980,   281,   260,  1945,   284,   965,  2433,   260,  2914,\n",
      "          198,  3659,   260,  2988,    30,   378, 10115,   980,   284,  2988,\n",
      "          359, 20657,  1127,  2067, 17400,    46, 22577, 17400,    46,   284,\n",
      "          198,    44, 11247,    46, 22577, 11247,    46, 12082,    28,  7827,\n",
      "           28,  2056,    30,    85,  1143,  2067, 17400,    46, 10115,   980,\n",
      "         1535, 22577, 17400,    46,   198,    44, 11247,    46,  2988,  1535,\n",
      "        22577, 11247, 19369,   198,   198,  6248,   441,  5051,   725,  2909,\n",
      "           30,  3315,   441,  2965, 11129,  2909,    30,   198,   198,  2683,\n",
      "          654,   597,   325,  1836,  3480,   411,   260,  2914,  8932,   346,\n",
      "          260,  3393,  2426,  4624,    30,   198, 11101,   260,  4624,   282,\n",
      "          260,  3480,    28,   564,  5482,   260,  1678,  1732,  3413,   411,\n",
      "          260,  2914,    28,   441,   260,  3480,    30,   198,   198, 26111,\n",
      "         1070,   731,  5258,  1163,    28,   469,  3124,  4624,   868,   325,\n",
      "           42,   198,    44, 17400,    46, 10115,   980,  1535, 22577, 17400,\n",
      "           46,   198,    44, 11247,    46,  2988,  1535, 22577, 11247,    46,\n",
      "          198,   198,  7334,  2426,   523,   325, 22440,   411, 28042,   260,\n",
      "          840,  5931,   826,   260,  2067, 11247,    46,  2026,  9617, 11247,\n",
      "           46, 12082,    30,   198,  1589,   314,  2609,   288,  1066,   260,\n",
      "         2120,  4624,    30,   198, 12839,    79,  1527,  4550,    79,  7638,\n",
      "         1519,   288,  1066,   260,  2426,  4624,   523,   966,   281,   253,\n",
      "        15919,    30,   198,     2,   198,     1,  4093,   198, 16865,   623,\n",
      "         7868,    42,   198,    33,    30,  2018,  1122,   359,  2355,   198,\n",
      "           34,    30,  2015,  2355,   359,   441,  6093,   198,   198, 14748,\n",
      "          357, 27177,  1066,   338,    42,   198,  4449,  1122,   359,   441,\n",
      "         6093,    47,   198,    24, 21350,  9230,   355,  2838,    25,     2,\n",
      "          198,     1,   520,  9531,   198])\n",
      "Decoded Input: system\n",
      "\n",
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
      "The assistant first thinks about the reasoning process in the mind and then provides the user\n",
      "with the answer. The reasoning process and answer are enclosed within <think> </think> and\n",
      "<answer> </answer> tags, respectively, i.e., <think> reasoning process here </think>\n",
      "<answer> answer here </answer>.\n",
      "\n",
      "Do not generate new code. Do not write python code.\n",
      "\n",
      "You may also be given examples by the user telling you the expected response format.\n",
      "Follow the format of the examples, but solve the specific problem asked by the user, not the examples.\n",
      "\n",
      "Very important - Remember again, your output format should be:\n",
      "<think> reasoning process here </think>\n",
      "<answer> answer here </answer>\n",
      "\n",
      "Your response will be scored by extracting the substring between the <answer>...</answer> tags.\n",
      "It is critical to follow the above format.\n",
      "feature_extraction_utilsling to follow the response format will result in a penalty.\n",
      "\n",
      "user\n",
      "Consider these statements:\n",
      "1. All children are animals\n",
      "2. Some animals are not doctors\n",
      "\n",
      "Does it logically follow that:\n",
      "Some children are not doctors?\n",
      "(Answer Yes or No)\n",
      "assistant\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    input_ids = batch['inputs']['input_ids']\n",
    "    attention_mask = batch['inputs']['attention_mask']  # optional, in case you need it\n",
    "\n",
    "    for i in range(2):\n",
    "        print(f\"Sample {i + 1}:\")\n",
    "        print(\"Input IDs:\", input_ids[i])\n",
    "        print(\"Decoded Input:\", tokenizer.decode(input_ids[i], skip_special_tokens=True))\n",
    "        print(\"-\" * 50)\n",
    "    break  # Only process the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Logits from model (pretend vocabulary = [\"mat\", \"rat\", \"cat\"])\n",
    "logits = torch.tensor([1.5, 0.2, 0.1], requires_grad=True)\n",
    "\n",
    "# Token \"mat\" = index 0\n",
    "target_index = 0\n",
    "\n",
    "# Compute softmax probs and log-prob\n",
    "log_probs = F.log_softmax(logits, dim=0)\n",
    "log_prob_mat = log_probs[target_index]\n",
    "\n",
    "# PPO-style advantage and ratio\n",
    "advantage = torch.tensor(1.0)\n",
    "old_prob = torch.tensor(0.6)\n",
    "current_prob = torch.exp(log_prob_mat)  #  0.7\n",
    "ratio = current_prob / old_prob         #  1.17\n",
    "\n",
    "# PPO loss (unclipped)\n",
    "loss = -ratio * advantage   # negative because we usually MINIMIZE loss\n",
    "\n",
    "# Backprop\n",
    "loss.backward()\n",
    "\n",
    "# Now, logits.grad shows how to change each logit!\n",
    "print(\"Logits:\", logits.detach().numpy())\n",
    "print(\"Gradient of loss w.r.t logits:\", logits.grad.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients for weight:\n",
      "tensor([[ 5.8691e-04,  5.8340e-02, -3.5837e-02,  1.0196e-01],\n",
      "        [-5.3065e-01,  6.5038e-01, -4.8656e-02, -5.6352e-01],\n",
      "        [ 5.3007e-01, -7.0872e-01,  8.4494e-02,  4.6156e-01]])\n",
      "Gradients for bias:\n",
      "tensor([-0.2074, -0.2106,  0.4180])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Shared model (like a single-layer \"transformer\" with 1 hidden layer)\n",
    "model = nn.Linear(4, 3)  # input: 4-dim, output: vocab of 3 tokens\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Fake input vectors for 2 tokens (e.g., embedding for \"mat\" and \"now\")\n",
    "x1 = torch.randn(1, 4, requires_grad=True)  # token 1\n",
    "x2 = torch.randn(1, 4, requires_grad=True)  # token 2\n",
    "\n",
    "# Forward pass: get logits for each token\n",
    "logits1 = model(x1)\n",
    "logits2 = model(x2)\n",
    "\n",
    "# Compute log probs\n",
    "log_probs1 = F.log_softmax(logits1, dim=-1)\n",
    "log_probs2 = F.log_softmax(logits2, dim=-1)\n",
    "\n",
    "# Assume \"mat\" = 0, \"now\" = 1\n",
    "target1 = torch.tensor([0])\n",
    "target2 = torch.tensor([1])\n",
    "\n",
    "# Per-token loss (negative log-likelihood)\n",
    "loss1 = F.nll_loss(log_probs1, target1)\n",
    "loss2 = F.nll_loss(log_probs2, target2)\n",
    "\n",
    "# Total loss = average\n",
    "loss = (loss1 + loss2) / 2\n",
    "\n",
    "# Backprop\n",
    "loss.backward()\n",
    "\n",
    "# Check gradients for model weights\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Gradients for {name}:\\n{param.grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1\n",
      "Question: Consider these statements:\n",
      "1. No students are humans\n",
      "2. All humans are chefs\n",
      "\n",
      "Does it logically follow that:\n",
      "Some chefs are humans?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 0, 'premise1': 'No students are humans', 'premise2': 'All humans are chefs', 'selected_premise': 2, 'conclusion': 'Some chefs are humans', 'is_valid': True, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 2\n",
      "Question: Consider these statements:\n",
      "1. All children are animals\n",
      "2. Some animals are not doctors\n",
      "\n",
      "Does it logically follow that:\n",
      "Some children are not doctors?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 1, 'premise1': 'All children are animals', 'premise2': 'Some animals are not doctors', 'conclusion': 'Some children are not doctors', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 3\n",
      "Question: Consider these statements:\n",
      "1. Some butterflies are not tigers\n",
      "2. No tigers are whales\n",
      "\n",
      "Does it logically follow that:\n",
      "Some butterflies are whales?\n",
      "(Answer Yes or No)\n",
      "Answer: No\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 2, 'premise1': 'Some butterflies are not tigers', 'premise2': 'No tigers are whales', 'conclusion': 'Some butterflies are whales', 'is_valid': False, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 4\n",
      "Question: Consider these statements:\n",
      "1. Some chefs are butterflies\n",
      "2. Some butterflies are elephants\n",
      "\n",
      "Does it logically follow that:\n",
      "Some butterflies are chefs?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 3, 'premise1': 'Some chefs are butterflies', 'premise2': 'Some butterflies are elephants', 'selected_premise': 1, 'conclusion': 'Some butterflies are chefs', 'is_valid': True, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 5\n",
      "Question: Consider these statements:\n",
      "1. All parents are insects\n",
      "2. All insects are children\n",
      "\n",
      "Does it logically follow that:\n",
      "Some parents are children?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 4, 'premise1': 'All parents are insects', 'premise2': 'All insects are children', 'conclusion': 'Some parents are children', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 6\n",
      "Question: Consider these statements:\n",
      "1. All birds are parents\n",
      "2. All parents are bees\n",
      "\n",
      "Does it logically follow that:\n",
      "Some birds are bees?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 5, 'premise1': 'All birds are parents', 'premise2': 'All parents are bees', 'conclusion': 'Some birds are bees', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 7\n",
      "Question: Consider these statements:\n",
      "1. All dolphins are dogs\n",
      "2. All dogs are teachers\n",
      "\n",
      "Does it logically follow that:\n",
      "All dolphins are teachers?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 6, 'premise1': 'All dolphins are dogs', 'premise2': 'All dogs are teachers', 'conclusion': 'All dolphins are teachers', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 8\n",
      "Question: Consider these statements:\n",
      "1. All parents are birds\n",
      "2. All birds are butterflies\n",
      "\n",
      "Does it logically follow that:\n",
      "Some parents are butterflies?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 7, 'premise1': 'All parents are birds', 'premise2': 'All birds are butterflies', 'conclusion': 'Some parents are butterflies', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 9\n",
      "Question: Consider these statements:\n",
      "1. Some elephants are not chefs\n",
      "2. Some chefs are fish\n",
      "\n",
      "Does it logically follow that:\n",
      "All elephants are fish?\n",
      "(Answer Yes or No)\n",
      "Answer: No\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 8, 'premise1': 'Some elephants are not chefs', 'premise2': 'Some chefs are fish', 'conclusion': 'All elephants are fish', 'is_valid': False, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 10\n",
      "Question: Consider these statements:\n",
      "1. No engineers are lions\n",
      "2. Some lions are dolphins\n",
      "\n",
      "Does it logically follow that:\n",
      "Some dolphins are lions?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 9, 'premise1': 'No engineers are lions', 'premise2': 'Some lions are dolphins', 'selected_premise': 2, 'conclusion': 'Some dolphins are lions', 'is_valid': True, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 11\n",
      "Question: Consider these statements:\n",
      "1. All chefs are adults\n",
      "2. Some adults are not lions\n",
      "\n",
      "Does it logically follow that:\n",
      "Some chefs are not lions?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 10, 'premise1': 'All chefs are adults', 'premise2': 'Some adults are not lions', 'conclusion': 'Some chefs are not lions', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 12\n",
      "Question: Consider these statements:\n",
      "1. All writers are spiders\n",
      "2. Some spiders are lions\n",
      "\n",
      "Does it logically follow that:\n",
      "Some writers are lions?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 11, 'premise1': 'All writers are spiders', 'premise2': 'Some spiders are lions', 'conclusion': 'Some writers are lions', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 13\n",
      "Question: Consider these statements:\n",
      "1. Some teachers are ants\n",
      "2. Some ants are not dolphins\n",
      "\n",
      "Does it logically follow that:\n",
      "Some ants are teachers?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 12, 'premise1': 'Some teachers are ants', 'premise2': 'Some ants are not dolphins', 'selected_premise': 1, 'conclusion': 'Some ants are teachers', 'is_valid': True, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 14\n",
      "Question: Consider these statements:\n",
      "1. Some grandparents are musicians\n",
      "2. No musicians are doctors\n",
      "\n",
      "Does it logically follow that:\n",
      "Some grandparents are not doctors?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 13, 'premise1': 'Some grandparents are musicians', 'premise2': 'No musicians are doctors', 'conclusion': 'Some grandparents are not doctors', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 15\n",
      "Question: Consider these statements:\n",
      "1. Some dolphins are mortals\n",
      "2. All mortals are horses\n",
      "\n",
      "Does it logically follow that:\n",
      "Some dolphins are horses?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 14, 'premise1': 'Some dolphins are mortals', 'premise2': 'All mortals are horses', 'conclusion': 'Some dolphins are horses', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 16\n",
      "Question: Consider these statements:\n",
      "1. Some children are fish\n",
      "2. Some fish are not humans\n",
      "\n",
      "Does it logically follow that:\n",
      "Some fish are children?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 15, 'premise1': 'Some children are fish', 'premise2': 'Some fish are not humans', 'selected_premise': 1, 'conclusion': 'Some fish are children', 'is_valid': True, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 17\n",
      "Question: Consider these statements:\n",
      "1. Some musicians are not writers\n",
      "2. Some writers are children\n",
      "\n",
      "Does it logically follow that:\n",
      "Some children are writers?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 16, 'premise1': 'Some musicians are not writers', 'premise2': 'Some writers are children', 'selected_premise': 2, 'conclusion': 'Some children are writers', 'is_valid': True, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 18\n",
      "Question: Consider these statements:\n",
      "1. Some programmers are grandparents\n",
      "2. All grandparents are spiders\n",
      "\n",
      "Does it logically follow that:\n",
      "No spiders are grandparents?\n",
      "(Answer Yes or No)\n",
      "Answer: No\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 17, 'premise1': 'Some programmers are grandparents', 'premise2': 'All grandparents are spiders', 'selected_premise': 2, 'conclusion': 'No spiders are grandparents', 'is_valid': False, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 19\n",
      "Question: Consider these statements:\n",
      "1. Some mammals are not animals\n",
      "2. All animals are doctors\n",
      "\n",
      "Does it logically follow that:\n",
      "Some doctors are animals?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 18, 'premise1': 'Some mammals are not animals', 'premise2': 'All animals are doctors', 'selected_premise': 2, 'conclusion': 'Some doctors are animals', 'is_valid': True, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 20\n",
      "Question: Consider these statements:\n",
      "1. Some elephants are artists\n",
      "2. Some artists are dolphins\n",
      "\n",
      "Does it logically follow that:\n",
      "Some artists are elephants?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 19, 'premise1': 'Some elephants are artists', 'premise2': 'Some artists are dolphins', 'selected_premise': 1, 'conclusion': 'Some artists are elephants', 'is_valid': True, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 21\n",
      "Question: Consider these statements:\n",
      "1. All artists are parents\n",
      "2. Some parents are engineers\n",
      "\n",
      "Does it logically follow that:\n",
      "Some artists are engineers?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 20, 'premise1': 'All artists are parents', 'premise2': 'Some parents are engineers', 'conclusion': 'Some artists are engineers', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 22\n",
      "Question: Consider these statements:\n",
      "1. All ants are animals\n",
      "2. All animals are lawyers\n",
      "\n",
      "Does it logically follow that:\n",
      "No ants are lawyers?\n",
      "(Answer Yes or No)\n",
      "Answer: No\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 21, 'premise1': 'All ants are animals', 'premise2': 'All animals are lawyers', 'conclusion': 'No ants are lawyers', 'is_valid': False, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 23\n",
      "Question: Consider these statements:\n",
      "1. Some horses are students\n",
      "2. No students are insects\n",
      "\n",
      "Does it logically follow that:\n",
      "Some horses are not insects?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 22, 'premise1': 'Some horses are students', 'premise2': 'No students are insects', 'conclusion': 'Some horses are not insects', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 24\n",
      "Question: Consider these statements:\n",
      "1. Some butterflies are animals\n",
      "2. No animals are lions\n",
      "\n",
      "Does it logically follow that:\n",
      "Some butterflies are not lions?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 23, 'premise1': 'Some butterflies are animals', 'premise2': 'No animals are lions', 'conclusion': 'Some butterflies are not lions', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 25\n",
      "Question: Consider these statements:\n",
      "1. All parents are mammals\n",
      "2. No mammals are bees\n",
      "\n",
      "Does it logically follow that:\n",
      "Some parents are not bees?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 24, 'premise1': 'All parents are mammals', 'premise2': 'No mammals are bees', 'conclusion': 'Some parents are not bees', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 26\n",
      "Question: Consider these statements:\n",
      "1. Some parents are students\n",
      "2. No students are butterflies\n",
      "\n",
      "Does it logically follow that:\n",
      "Some parents are not butterflies?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 25, 'premise1': 'Some parents are students', 'premise2': 'No students are butterflies', 'conclusion': 'Some parents are not butterflies', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 27\n",
      "Question: Consider these statements:\n",
      "1. Some spiders are not lions\n",
      "2. Some lions are students\n",
      "\n",
      "Does it logically follow that:\n",
      "Some spiders are students?\n",
      "(Answer Yes or No)\n",
      "Answer: No\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 26, 'premise1': 'Some spiders are not lions', 'premise2': 'Some lions are students', 'conclusion': 'Some spiders are students', 'is_valid': False, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 28\n",
      "Question: Consider these statements:\n",
      "1. Some children are philosophers\n",
      "2. Some philosophers are scientists\n",
      "\n",
      "Does it logically follow that:\n",
      "Some scientists are philosophers?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 27, 'premise1': 'Some children are philosophers', 'premise2': 'Some philosophers are scientists', 'selected_premise': 2, 'conclusion': 'Some scientists are philosophers', 'is_valid': True, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 29\n",
      "Question: Consider these statements:\n",
      "1. All students are animals\n",
      "2. No animals are spiders\n",
      "\n",
      "Does it logically follow that:\n",
      "No students are spiders?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 28, 'premise1': 'All students are animals', 'premise2': 'No animals are spiders', 'conclusion': 'No students are spiders', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 30\n",
      "Question: Consider these statements:\n",
      "1. No dogs are lions\n",
      "2. No lions are mortals\n",
      "\n",
      "Does it logically follow that:\n",
      "All lions are dogs?\n",
      "(Answer Yes or No)\n",
      "Answer: No\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 29, 'premise1': 'No dogs are lions', 'premise2': 'No lions are mortals', 'selected_premise': 1, 'conclusion': 'All lions are dogs', 'is_valid': False, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 31\n",
      "Question: Consider these statements:\n",
      "1. All parents are artists\n",
      "2. No artists are birds\n",
      "\n",
      "Does it logically follow that:\n",
      "Some parents are not birds?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 30, 'premise1': 'All parents are artists', 'premise2': 'No artists are birds', 'conclusion': 'Some parents are not birds', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 32\n",
      "Question: Consider these statements:\n",
      "1. Some chefs are students\n",
      "2. All students are lions\n",
      "\n",
      "Does it logically follow that:\n",
      "Some chefs are not lions?\n",
      "(Answer Yes or No)\n",
      "Answer: No\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 31, 'premise1': 'Some chefs are students', 'premise2': 'All students are lions', 'conclusion': 'Some chefs are not lions', 'is_valid': False, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 33\n",
      "Question: Consider these statements:\n",
      "1. Some lions are students\n",
      "2. No students are dogs\n",
      "\n",
      "Does it logically follow that:\n",
      "No dogs are students?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 32, 'premise1': 'Some lions are students', 'premise2': 'No students are dogs', 'selected_premise': 2, 'conclusion': 'No dogs are students', 'is_valid': True, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 34\n",
      "Question: Consider these statements:\n",
      "1. All ants are bees\n",
      "2. Some bees are spiders\n",
      "\n",
      "Does it logically follow that:\n",
      "Some bees are ants?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 33, 'premise1': 'All ants are bees', 'premise2': 'Some bees are spiders', 'selected_premise': 1, 'conclusion': 'Some bees are ants', 'is_valid': True, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 35\n",
      "Question: Consider these statements:\n",
      "1. Some fish are spiders\n",
      "2. All spiders are reptiles\n",
      "\n",
      "Does it logically follow that:\n",
      "No spiders are fish?\n",
      "(Answer Yes or No)\n",
      "Answer: No\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 34, 'premise1': 'Some fish are spiders', 'premise2': 'All spiders are reptiles', 'selected_premise': 1, 'conclusion': 'No spiders are fish', 'is_valid': False, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 36\n",
      "Question: Consider these statements:\n",
      "1. All lawyers are dogs\n",
      "2. Some dogs are musicians\n",
      "\n",
      "Does it logically follow that:\n",
      "Some dogs are lawyers?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 35, 'premise1': 'All lawyers are dogs', 'premise2': 'Some dogs are musicians', 'selected_premise': 1, 'conclusion': 'Some dogs are lawyers', 'is_valid': True, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 37\n",
      "Question: Consider these statements:\n",
      "1. All musicians are philosophers\n",
      "2. No philosophers are mammals\n",
      "\n",
      "Does it logically follow that:\n",
      "No musicians are mammals?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 36, 'premise1': 'All musicians are philosophers', 'premise2': 'No philosophers are mammals', 'conclusion': 'No musicians are mammals', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 38\n",
      "Question: Consider these statements:\n",
      "1. Some doctors are not ants\n",
      "2. No ants are birds\n",
      "\n",
      "Does it logically follow that:\n",
      "All doctors are birds?\n",
      "(Answer Yes or No)\n",
      "Answer: No\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 37, 'premise1': 'Some doctors are not ants', 'premise2': 'No ants are birds', 'conclusion': 'All doctors are birds', 'is_valid': False, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 39\n",
      "Question: Consider these statements:\n",
      "1. All chefs are insects\n",
      "2. No insects are whales\n",
      "\n",
      "Does it logically follow that:\n",
      "Some chefs are not whales?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 38, 'premise1': 'All chefs are insects', 'premise2': 'No insects are whales', 'conclusion': 'Some chefs are not whales', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 40\n",
      "Question: Consider these statements:\n",
      "1. All lions are spiders\n",
      "2. No spiders are cats\n",
      "\n",
      "Does it logically follow that:\n",
      "No lions are cats?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 39, 'premise1': 'All lions are spiders', 'premise2': 'No spiders are cats', 'conclusion': 'No lions are cats', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 41\n",
      "Question: Consider these statements:\n",
      "1. No doctors are elephants\n",
      "2. No elephants are lions\n",
      "\n",
      "Does it logically follow that:\n",
      "All lions are elephants?\n",
      "(Answer Yes or No)\n",
      "Answer: No\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 40, 'premise1': 'No doctors are elephants', 'premise2': 'No elephants are lions', 'selected_premise': 2, 'conclusion': 'All lions are elephants', 'is_valid': False, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 42\n",
      "Question: Consider these statements:\n",
      "1. All elephants are spiders\n",
      "2. All spiders are grandparents\n",
      "\n",
      "Does it logically follow that:\n",
      "All grandparents are spiders?\n",
      "(Answer Yes or No)\n",
      "Answer: No\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 41, 'premise1': 'All elephants are spiders', 'premise2': 'All spiders are grandparents', 'selected_premise': 2, 'conclusion': 'All grandparents are spiders', 'is_valid': False, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 43\n",
      "Question: Consider these statements:\n",
      "1. Some animals are children\n",
      "2. No children are elephants\n",
      "\n",
      "Does it logically follow that:\n",
      "Some children are animals?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 42, 'premise1': 'Some animals are children', 'premise2': 'No children are elephants', 'selected_premise': 1, 'conclusion': 'Some children are animals', 'is_valid': True, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 44\n",
      "Question: Consider these statements:\n",
      "1. Some musicians are not philosophers\n",
      "2. Some philosophers are dogs\n",
      "\n",
      "Does it logically follow that:\n",
      "No musicians are dogs?\n",
      "(Answer Yes or No)\n",
      "Answer: No\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 43, 'premise1': 'Some musicians are not philosophers', 'premise2': 'Some philosophers are dogs', 'conclusion': 'No musicians are dogs', 'is_valid': False, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 45\n",
      "Question: Consider these statements:\n",
      "1. All humans are dolphins\n",
      "2. Some dolphins are not dogs\n",
      "\n",
      "Does it logically follow that:\n",
      "Some humans are not dogs?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 44, 'premise1': 'All humans are dolphins', 'premise2': 'Some dolphins are not dogs', 'conclusion': 'Some humans are not dogs', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 46\n",
      "Question: Consider these statements:\n",
      "1. Some doctors are musicians\n",
      "2. Some musicians are whales\n",
      "\n",
      "Does it logically follow that:\n",
      "Some whales are musicians?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 45, 'premise1': 'Some doctors are musicians', 'premise2': 'Some musicians are whales', 'selected_premise': 2, 'conclusion': 'Some whales are musicians', 'is_valid': True, 'type': 'inversion'}\n",
      "--------------------------------------------------\n",
      "Sample 47\n",
      "Question: Consider these statements:\n",
      "1. All insects are musicians\n",
      "2. No musicians are cats\n",
      "\n",
      "Does it logically follow that:\n",
      "No insects are cats?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 46, 'premise1': 'All insects are musicians', 'premise2': 'No musicians are cats', 'conclusion': 'No insects are cats', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 48\n",
      "Question: Consider these statements:\n",
      "1. Some grandparents are not lawyers\n",
      "2. Some lawyers are teachers\n",
      "\n",
      "Does it logically follow that:\n",
      "No grandparents are teachers?\n",
      "(Answer Yes or No)\n",
      "Answer: No\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 47, 'premise1': 'Some grandparents are not lawyers', 'premise2': 'Some lawyers are teachers', 'conclusion': 'No grandparents are teachers', 'is_valid': False, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 49\n",
      "Question: Consider these statements:\n",
      "1. All writers are grandparents\n",
      "2. All grandparents are horses\n",
      "\n",
      "Does it logically follow that:\n",
      "Some writers are horses?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 48, 'premise1': 'All writers are grandparents', 'premise2': 'All grandparents are horses', 'conclusion': 'Some writers are horses', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n",
      "Sample 50\n",
      "Question: Consider these statements:\n",
      "1. All grandparents are artists\n",
      "2. Some artists are not scientists\n",
      "\n",
      "Does it logically follow that:\n",
      "Some grandparents are not scientists?\n",
      "(Answer Yes or No)\n",
      "Answer: Yes\n",
      "Metadata: {'source_dataset': 'syllogism', 'source_index': 49, 'premise1': 'All grandparents are artists', 'premise2': 'Some artists are not scientists', 'conclusion': 'Some grandparents are not scientists', 'is_valid': True, 'type': 'syllogism'}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Step 1: Install Reasoning Gym (if not already installed)\n",
    "# !pip install reasoning-gym\n",
    "\n",
    "# Step 2: Import the library\n",
    "import reasoning_gym\n",
    "\n",
    "# Step 3: Generate a syllogism dataset\n",
    "dataset = reasoning_gym.create_dataset(\n",
    "    name='syllogism',  # the reasoning task you want\n",
    "    size=50,                 # number of samples to generate\n",
    "    seed=42                 # optional: for reproducibility\n",
    ")\n",
    "\n",
    "# Step 4: Print the generated questions and answers\n",
    "for i, sample in enumerate(dataset):\n",
    "    print(f\"Sample {i + 1}\")\n",
    "    print(\"Question:\", sample['question'])\n",
    "    print(\"Answer:\", sample['answer'])\n",
    "    print(\"Metadata:\", sample['metadata'])  # optional, includes things like difficulty\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 10 files: 100%|| 10/10 [00:00<00:00, 24.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model repo downloaded to: /home/athenaik/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "# This will download the whole repo and give you the local path\n",
    "local_path = snapshot_download(repo_id=model_name)\n",
    "\n",
    "print(f\"Model repo downloaded to: {local_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Tensor device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "x = torch.randn(10).to(device)\n",
    "print(\"Tensor device:\", x.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
